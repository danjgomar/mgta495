{"title":"A Replication of Karlan and List (2007)","markdown":{"yaml":{"title":"A Replication of Karlan and List (2007)","author":"Daniel Garcia","date":"today","callout-appearance":"minimal"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the *American Economic Review* in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nTo meticulously assess the influence of different incentives on donor behavior, Karlan and List structured their experiment with precision and thoroughness. Each recipient in the experiment was selected from a pool of individuals who had previously donated to the organization, ensuring that all participants had a baseline familiarity with and a prior engagement in charitable giving. The allocation of the letters was performed randomly to uphold the integrity of the experimental conditions and mitigate any selection bias. The key variation among the letters lay in the type of incentive they presented, which allowed the researchers to isolate the effect of these incentives from other factors that might influence a donor's decision to give. By embedding these variations subtly within the letters, the experiment not only preserved the naturalistic setting of the solicitation but also minimized any potential disruption to the donor's experience that could arise from overt experimental cues. This methodological rigor underpins the reliability of the study's findings, providing a clear lens through which to view how different motivational strategies affect the willingness of individuals to contribute financially to charitable causes.\n\n\nThis paper presents the results of a large-scale natural field experiment testing changes in revenue per solicitation and response rates given different types and levels of matching grants/gifts conditional on charitable giving. This is in order to provide insight to research in fundraising models and measures of non-market valuation for cost-benefit analyses. Of a sample of 50,083 individuals who have given to the organization since 1991, randomized and assigned 67% into \"match\" treatment group and 33% into control group, of which the \"match\" treatment group was offered a matching grant conditional on their donation. The \"match\" group was divded evenly between various sizes of the matching ratio (\\$3:\\$1, \\$2:\\$1, and \\$1:\\$1), the maximum size of the matching gift across all donations (\\$25,000, \\$50,000, and \\$100,000), and the example donation amount suggested to the donor (the individual's highest previous contribution, 1.25 times their highest previous contribution, and 1.5 times their highest previous contribution). All individuals received a four page letter identical in all respects except two: (a) the treatment let ters included an additional paragraph inserted at the top of the second page that announced that a \"concerned fellow member\" will match their donation, and (b) the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization. Outcome measures were donation response rates (donated or did not donate) and dollars donated.\n\nThis project seeks to replicate their results. However, because we are using a different software (R) to replicate the experiment. We got a different results because there are different estimators while we are running the probit, when in STATA we just need to use the command \"dprobit\".\n\n## Data\n\n### Description\n\n```{r include=FALSE}\n# Load necessary libraries\nlibrary(dplyr)     \nlibrary(ggplot2)  \nlibrary(foreign) \nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(broom)\nlibrary(stats)\n\n# Read the Stata data file into R\n\ndata <- read.dta(\"karlan_list_2007.dta\")\n```\n\n```{r include=FALSE}\n# Summary statistics for all observations\nsummary(data[, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n\n# Summary statistics for observations where treatment is 1\nsummary(data[data$treatment == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n\n# Summary statistics for observations where control is 1\nsummary(data[data$control == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n```\n\n```{r echo=FALSE, warning=FALSE}\n# Convert necessary columns to numeric if they're not already\ndata$size <- as.numeric(data$size)\n\n# Calculate means for all observations\nmeans_all <- colMeans(data[, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Calculate means for observations where treatment is 1\nmeans_treatment <- colMeans(data[data$treatment == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Calculate means for observations where control is 1\nmeans_control <- colMeans(data[data$control == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Combine means into a data frame\nmeans_table <- data.frame(\n  Variable = c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\"),\n  All_Observations = means_all,\n  Treatment = means_treatment,\n  Control = means_control\n)\n\n# Render the table nicely\nkable(means_table, \"html\") %>%\n  kable_styling(full_width = FALSE)\n```\n\n\n```{r echo=FALSE, warning=FALSE}\n\n# Create histogram\nhistogram <- ggplot(data, aes(x = amount, fill = treatment)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"black\") +\n  labs(title = \"Amount of Donation by Treatment Group\", x = \"Amount\", y = \"Frequency\") +\n  facet_wrap(~ treatment) +  \n  theme_minimal()\n\n# Display histogram\nprint(histogram)\n```\n\n\n```{r echo=FALSE}\n# Create scatterplot matrix for selected continuous variables\nscatterplot_matrix <- ggplot(data, aes(x = mrm2, y = amount, color = ratio)) +\n  geom_point() +\n  labs(title = \"Scatterplot Matrix\", x = \"Number of months since last donation\", y = \"Amount\") +\n  theme_minimal()\n\nprint(scatterplot_matrix)\n```\n\n::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|-------------------|-----------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n:::\n\n### Balance Test\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n```{r echo=FALSE}\n# Define the variables to test\nvariables_to_test <- c(\"female\", \"couple\", \"dormant\", \"nonlit\", \"cases\", \"statecnt\", \"stateresponse\", \"red0\", \"blue0\", \"redcty\",\"pop_propurban\", \"psch_atlstba\", \"powner\", \"median_hhincome\", \"ave_hh_sz\", \"page18_39\", \"pblack\", \"pwhite\")\n\n# Initialize an empty data frame to store results\nbalance_table <- data.frame(Variable = character(),\n                            Diff = numeric(),\n                            p_Value = numeric(),\n                            stringsAsFactors = FALSE)\n\n# Loop over variables\nfor (var in variables_to_test) {\n  # T-Test\n  t_test_result <- t.test(as.numeric(data[[var]]) ~ data$treatment)\n  \n  # Linear Regression\n  reg_model <- lm(as.formula(paste(var, \"~ treatment\")), data = data)\n  tidy_reg <- tidy(reg_model)\n  \n  # Extract coefficients and p-values\n  reg_coefficient <- tidy_reg$estimate[2]  # treatment coefficient\n  reg_p_value <- tidy_reg$p.value[2]  # p-value for treatment\n  \n  # Update the balance table\n  balance_table <- rbind(balance_table, data.frame(\n    Variable = var,\n    Diff = reg_coefficient,\n    p_Value = reg_p_value\n  ))\n}\n\n# Print the balance table\n#print(balance_table)\n# Create the table using knitr and enhance it with kableExtra\nkable_table <- kable(balance_table, format = \"html\", caption = \"Balance Test Results\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE) %>%\n  column_spec(1, bold = TRUE, color = \"blue\") %>%  \n  column_spec(2:3, background = \"#f7f7f7\")  \n\nkable_table\n```\n\n\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n```{r echo=FALSE}\n\n# Compute proportions of people who donated in treatment and control groups\nprop_donated <- tapply(data$amount, data$treatment, mean)\n\n# Create barplot\nbarplot(prop_donated, \n        names.arg = c(\"Control\", \"Treatment\"), \n        xlab = \"Group\", \n        ylab = \"Proportion of Donated\",\n        col = c(\"blue\", \"green\"),\n        ylim = c(0, 1),\n        main = \"Proportion of Donated in Treatment and Control Groups\")\n```\n\n\n```{r echo=FALSE}\n\n# T-test between treatment and control groups\nttest_result <- t.test(amount ~ treatment, data = data)\n\n# Extract relevant information\nestimate <- ttest_result$estimate\np_value <- ttest_result$p.value\nconf_int <- ttest_result$conf.int\nconf_level <- attr(conf_int, \"conf.level\")\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Group\" = c(\"Control\", \"Treatment\"),\n  \"Estimate\" = estimate,\n  \"p-value\" = p_value\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n\n```\n\n\n```{r echo=FALSE}\n# Fit linear regression model\nmodel <- lm(amount ~ treatment, data = data)\n\n# Extract coefficients, standard errors, t-values, and p-values\ncoefficients <- summary(model)$coefficients[, 1]\nstd_errors <- summary(model)$coefficients[, 2]\nt_values <- summary(model)$coefficients[, 3]\np_values <- summary(model)$coefficients[, 4]\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Coefficient\" = coefficients,\n  \"Std. Error\" = std_errors,\n  \"T-value\" = t_values,\n  \"P-value\" = p_values\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n\n```\n\nThe previous table shows that there is a positive effect of the treatment on the proportion of donations, which is significant at 90% which does not make it statistically powerful.\n\n```{r include=FALSE}\n#*todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.*\n# Model 1: Probit model without any subgroup analysis\nmodel1 <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"))\n# Calculate marginal effects\nmarginal_effects1 <- predict(model1, type = \"response\") * coef(model1)[\"amount\"]\n\n# Fit probit model\nmodel <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Display model summary\nsummary(model)\n\n# Model 2: Probit model for individuals where dormant == 1\nmodel2 <- glm(treatment ~ amount, data = subset(data, dormant == 1), family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n\n# Model 3: Probit model for individuals where dormant == 0\nmodel3 <- glm(treatment ~ amount, data = subset(data, dormant == 0), family = binomial(link = \"probit\"))\n\n\n# Summarize the results\n\nsummary(marginal_effects1) \nsummary(model)\nsummary(model2) \nsummary(model3)\n```\n\n### Replication of the model\n\n```{r echo=FALSE}\n# Fit probit model\nmodel <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Model 2: Probit model for individuals where dormant == 1\nmodel2 <- glm(treatment ~ amount, data = subset(data, dormant == 1), family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Model 3: Probit model for individuals where dormant == 0\nmodel3 <- glm(treatment ~ amount, data = subset(data, dormant == 0), family = binomial(link = \"probit\"))\n\n# Extract coefficients, standard errors, z-values, and p-values from model summaries\ncoef_model <- coef(summary(model))\ncoef_model2 <- coef(summary(model2))\ncoef_model3 <- coef(summary(model3))\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Model\" = c(\"Model 1\", \"Model 2 (dormant == 1)\", \"Model 3 (dormant == 0)\"),\n  \"Estimate\" = c(coef_model[\"amount\", 1], coef_model2[\"amount\", 1], coef_model3[\"amount\", 1]),\n  \"Std. Error\" = c(coef_model[\"amount\", 2], coef_model2[\"amount\", 2], coef_model3[\"amount\", 2]),\n  \"Z-value\" = c(coef_model[\"amount\", 3], coef_model2[\"amount\", 3], coef_model3[\"amount\", 3]),\n  \"P-value\" = c(coef_model[\"amount\", 4], coef_model2[\"amount\", 4], coef_model3[\"amount\", 4])\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n```\n\nThere is a problem with R because it gives a different estimator than the one that STATA provides and that does not allow to get the proper replication.\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n```{r include=FALSE}\n#*todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the \"figures suggest\" comment the authors make on page 8?*\n\n# Subset the data for each match ratio group\ndata_ratio_1_1 <- subset(data, ratio2 == 0)  # Group where ratio is 1:1\ndata_ratio_2_1 <- subset(data, ratio2 == 1)  # Group where ratio is 2:1\n\n# Conduct t-test comparing donation rates between 1:1 match ratio group and 2:1 match ratio group\nttest_result <- t.test(amount ~ ratio2, data = data)\n\n# Display t-test results\nttest_result\n```\n\n```{r include=FALSE}\n# Subset the data based on match ratios\n#group_1_1 <- data$gave[data$match_ratio == \"1:1\"]\n#group_2_1 <- data$gave[data$match_ratio == \"2:1\"]\n#group_3_1 <- data$gave[data$match_ratio == \"3:1\"]\n\n# Perform t-tests\n#ttest_1_1_vs_2_1 <- t.test(group_1_1, group_2_1)\n#ttest_2_1_vs_3_1 <- t.test(group_2_1, group_3_1)\n\n# Output the results of the t-tests\n#print(ttest_1_1_vs_2_1)\n#print(ttest_2_1_vs_3_1)\n```\n\n\n```{r include=FALSE}\n#*todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision.*\n```\n\n\nIn analyzing the impact of different match ratios on the likelihood of donations using logistic regression, we observe varying degrees of effectiveness. The coefficients for the individual match ratios (ratio1, ratio2, and ratio3) indicate a progressive increase in the log odds of donating as the match ratio increases. Specifically, ratio1 (1:1 match) shows a very minimal increase in log odds (0.006564), suggesting that this match ratio barely affects the probability of donating compared to the baseline. In contrast, ratio2 (2:1 match) and ratio3 (3:1 match) exhibit more substantial effects with coefficients of 0.12244 and 0.12838, respectively, indicating a clearer positive influence on donation behavior. These coefficients suggest that higher match ratios are somewhat more effective at encouraging donations.\n\nThe full model, which assesses the collective impact of varying match ratios treated as a single categorical variable, shows a significant coefficient (0.08470). This significance indicates that different match ratios, when considered together, have a statistically significant effect on the likelihood of donating compared to the baseline. This outcome implies that while the individual effects of each match ratio are relatively modest, the overall strategy of employing match ratios is effective.\n\nHowever, the statistical precision of these coefficients, typically assessed by p-values and confidence intervals, is not detailed in the results provided. For a comprehensive interpretation, examining these statistical measures would be crucial. They would help confirm the reliability of the observed effects by showing the probability that these effects could be due to chance (p-values) and the range within which the true effects are likely to lie with a certain level of confidence (confidence intervals). Thus, while the regression results suggest some effectiveness of higher match ratios, a detailed examination of the statistical precision is essential to fully validate these conclusions.\n\n```{r echo=FALSE}\n# Logistic regression model\n# Create dummy variables\ndata$ratio1 <- ifelse(data$ratio == \"1\", 1, 0)\ndata$ratio2 <- ifelse(data$ratio == \"2\", 1, 0)\ndata$ratio3 <- ifelse(data$ratio == \"3\", 1, 0)\n\nmodel1 <- glm(gave ~ ratio1 , family = binomial(), data = data)\nsummary(model1)\n\nmodel2 <- glm(gave ~ ratio2 , family = binomial(), data = data)\nsummary(model2)\n\nmodel3 <- glm(gave ~ ratio3 , family = binomial(), data = data)\nsummary(model3)\n\nmodel <- glm(gave ~ ratio , family = binomial(), data = data)\nsummary(model)\n```\n\n```{r echo=FALSE}\n# Function to extract relevant data from model summary\nextract_model_info <- function(model) {\n  coef_table <- summary(model)$coefficients\n  data.frame(\n    Term = rownames(coef_table),\n    Estimate = coef_table[, \"Estimate\"],\n    Std_Error = coef_table[, \"Std. Error\"],\n    z_value = coef_table[, \"z value\"],\n    P_value = coef_table[, \"Pr(>|z|)\"],\n    stringsAsFactors = FALSE\n  )\n}\n\n# Extracting results for each model\nresults1 <- extract_model_info(model1)\nresults2 <- extract_model_info(model2)\nresults3 <- extract_model_info(model3)\n#results_full <- extract_model_info(model)\n\n# Add model identification\n#results1$Model <- \"Model 1 (ratio1)\"\n#results2$Model <- \"Model 2 (ratio2)\"\n#results3$Model <- \"Model 3 (ratio3)\"\n#results_full$Model <- \"Full Model (categorical ratio)\"\n\n# Combine all results into one data frame\nall_results <- rbind(results1, results2, results3)\n\n# Create a kable table and enhance it with kableExtra\nkable_table <- kable(all_results, format = \"html\", caption = \"Summary of Logistic Regression Models\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE) %>%\n  column_spec(1, bold = TRUE) %>%  # Make model column bold\n  column_spec(2:6, background = \"#f7f7f7\")  # Apply background color to data columns\n\n# Render the table in HTML\nkable_table\n```\n\n\n```{r echo=FALSE}\n#*todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?*\n#*\n# 1. Direct calculation from the data\nresponse_rate_1 <- mean(data$gave[data$ratio == \"1\"])\nresponse_rate_2 <- mean(data$gave[data$ratio == \"2\"])\nresponse_rate_3 <- mean(data$gave[data$ratio == \"3\"])\n\ndiff_1_2 <- response_rate_2 - response_rate_1  # Difference between 1:1 and 2:1 match ratios\ndiff_2_3 <- response_rate_3 - response_rate_2  # Difference between 2:1 and 3:1 match ratios\n\n# Print direct computation results\nprint(paste(\"Direct Difference in response rates between 1:1 and 2:1 match ratios:\", diff_1_2))\nprint(paste(\"Direct Difference in response rates between 2:1 and 3:1 match ratios:\", diff_2_3))\n\n# 2. Logistic Regression to find differences using model coefficients\n# First, ensure 'ratio' is a factor if not already\ndata$ratio <- as.factor(data$ratio)\n\n# Fit the model\nmodel <- glm(gave ~ ratio, family = binomial(), data = data)\n\n# Print summary to view coefficient names\nprint(summary(model))\n\n# Coefficient interpretation (assuming '1' is the reference category)\nlog_odds_diff_1_2 <- coef(model)[\"ratio2\"]  # log odds of '2' relative to '1'\nlog_odds_diff_2_3 <- coef(model)[\"ratio3\"] - coef(model)[\"ratio2\"]  # log odds of '3' relative to '2'\n\n# Print model-based log odds differences\nprint(paste(\"Model-based Difference in log odds between 1:1 and 2:1 match ratios:\", log_odds_diff_1_2))\nprint(paste(\"Model-based Difference in log odds between 2:1 and 3:1 match ratios:\", log_odds_diff_2_3))\n\n# Convert log odds to probabilities for clearer interpretation\nprob_diff_1_2 <- exp(log_odds_diff_1_2) / (1 + exp(log_odds_diff_1_2))\nprob_diff_2_3 <- exp(log_odds_diff_2_3) / (1 + exp(log_odds_diff_2_3))\n\n# Print model-based probability differences\nprint(paste(\"Model-based Difference in probability estimates between 1:1 and 2:1 match ratios:\", prob_diff_1_2))\nprint(paste(\"Model-based Difference in probability estimates between 2:1 and 3:1 match ratios:\", prob_diff_2_3))\n```\n\nThe analysis of the effectiveness of different sizes of matched donations reveals minimal impact on increasing donor response rates. Direct comparison of response rates shows only a slight improvement when the match ratio is increased from 1:1 to 2:1, and an even smaller increase from 2:1 to 3:1, suggesting negligible practical benefits from increasing the match size within these ranges. Although the logistic regression model indicates a moderate improvement in log odds of donating when moving from a 1:1 to a 2:1 match ratio, this result does not align closely with the very small changes observed directly in the data. Furthermore, the probability changes suggested by the model seem overly optimistic and likely reflect a misunderstanding or misinterpretation of the log odds conversion. Overall, these findings suggest that larger match ratios, within the bounds studied, do not significantly enhance the likelihood of donations. This implies that non-profits might need to consider other strategies or focus on how match offers are communicated rather than simply increasing the match ratio to boost donor engagement.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n```{r include=FALSE}\n#todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?*\n\n# Load the broom package\nlibrary(broom)\n\n# Run the linear regression\nlm_model <- lm(amount ~ treatment, data = data)\n\n# Convert the summary of the linear regression model into a tidy data frame\ntidy_lm_model <- tidy(lm_model)\n\n```\n\nAs it was previously shown, the treatment improves the outcomes (amount of donations) in 15 percentage points and it is statistically significant at 90%. Therefore, we can rely on the fact that this type of intervention might result in a proper result.\n\n```{r results='asis', echo=FALSE}\nkable(tidy_lm_model)\n```\n\nBased on this constraint, where we are limiting the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. We can interpret that the treatment is negative, but not statistically significant. Therefore, if we implement this type of program, it would reduce the amount of donations.\n\n```{r include=FALSE}\n# Subset the data to include only people who made a donation\ndonation_data <- subset(data, gave == 1)\n\n# Run the linear regression\nlm_model_donation <- lm(amount ~ treatment, data = donation_data)\n\n# Print the regression summary\nsummary(lm_model_donation)\n\ntidy_lm_model_donation <- tidy(lm_model_donation)\n```\n\n```{r results='asis', echo=FALSE}\nkable(tidy_lm_model_donation)\n```\n\n\n```{r echo=FALSE}\n# Calculate sample average donation amount for treatment and control groups\navg_donation_treatment <- mean(donation_data$amount[donation_data$treatment == 1])\navg_donation_control <- mean(donation_data$amount[donation_data$treatment == 0])\n\n# Plot histogram for treatment group\nhist_treatment <- ggplot(donation_data[donation_data$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  geom_vline(xintercept = avg_donation_treatment, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Treatment\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n# Plot histogram for control group\nhist_control <- ggplot(donation_data[donation_data$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  geom_vline(xintercept = avg_donation_control, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Control\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n# Display plots side by side\ngrid.arrange(hist_treatment, hist_control, nrow = 1)\n```\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\nThe next graph shows that with higher number of observations it would be possible to get to the true value of the mean that should be expected to get if we have the population values. However, because it was worked with a sample, it is just an estimation\n\n```{r echo=FALSE}\n\n#*to do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.*\n\n# Estimate mean and standard deviation for the control group\ncontrol_mean <- mean(data$control)\ncontrol_sd <- sd(data$control)\n\n# Estimate mean and standard deviation for the treatment group\ntreatment_mean <- mean(data$treatment)\ntreatment_sd <- sd(data$treatment)\n\n\n# Simulate draws from the control distribution\ncontrol_draws <- rnorm(10000, mean = control_mean, sd = control_sd)  # Assuming control_mean and control_sd are the mean and standard deviation of the control distribution\n\n# Simulate draws from the treatment distribution\ntreatment_draws <- rnorm(10000, mean = treatment_mean, sd = treatment_sd)  # Assuming treatment_mean and treatment_sd are the mean and standard deviation of the treatment distribution\n\n# Calculate vector of differences\ndifferences <- treatment_draws - control_draws\n\n# Calculate cumulative average of differences\ncumulative_avg <- cumsum(differences) / seq_along(differences)\n\n# Plot cumulative average of differences\nplot(cumulative_avg, type = \"l\", xlab = \"Number of Draws\", ylab = \"Cumulative Average Difference\", main = \"Cumulative Average Difference between Treatment and Control\")\n```\n\n\n### Central Limit Theorem\n\n```{r include=FALSE}\n# Function to simulate draws and calculate average difference\nsimulate_avg_difference <- function(sample_size, num_simulations) {\n  avg_differences <- numeric(num_simulations)\n  for (i in 1:num_simulations) {\n    control_draws <- rnorm(sample_size, mean = control_mean, sd = control_sd)\n    treatment_draws <- rnorm(sample_size, mean = treatment_mean, sd = treatment_sd)\n    avg_differences[i] <- mean(treatment_draws - control_draws)\n  }\n  return(avg_differences)\n}\n\n# Sample sizes\nsample_sizes <- c(50, 200, 500, 1000)\n\n# Number of simulations\nnum_simulations <- 1000\n\n# Plot histograms for each sample size\npar(mfrow = c(2, 2))  # Arrange plots in 2x2 grid\nfor (size in sample_sizes) {\n  avg_differences <- simulate_avg_difference(size, num_simulations)\n  hist(avg_differences, main = paste(\"Sample Size:\", size), xlab = \"Average Difference\", col = \"skyblue\", breaks = 30)\n}\n```\n\nIn the next graphs, it is possible to identify that with higher number observations the distribution becomes more efficient because it is concentrated in one spot where the true value of the populatoin should be identify. That would mean that the variance is lower than those situations where the sample is not big enough and that prevent to generate a good estimator. In those cases, the zero is located in the tail and when the sample increases, the zero is located out of the distribution which will mean that it would be an outlier.\n\n```{r echo=FALSE}\n\n#*to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the \"middle\" of the distribution or whether it's in the \"tail.\"*\n\n# Function to simulate draws and calculate average difference\nsimulate_avg_difference <- function(sample_size, num_simulations) {\n  avg_differences <- numeric(num_simulations)\n  for (i in 1:num_simulations) {\n    control_draws <- rnorm(sample_size, mean = control_mean, sd = control_sd)\n    treatment_draws <- rnorm(sample_size, mean = treatment_mean, sd = treatment_sd)\n    avg_differences[i] <- mean(treatment_draws - control_draws)\n  }\n  return(avg_differences)\n}\n\n# Sample sizes\nsample_sizes <- c(50, 200, 500, 1000)\n\n# Number of simulations\nnum_simulations <- 1000\n\n# Plot histograms for each sample size\npar(mfrow = c(2, 2))  # Arrange plots in 2x2 grid\nfor (size in sample_sizes) {\n  avg_differences <- simulate_avg_difference(size, num_simulations)\n  hist(avg_differences, main = paste(\"Sample Size:\", size), xlab = \"Average Difference\", col = \"skyblue\", breaks = 30, xlim = c(0, 0.7))\n}\n```\n\n","srcMarkdownNoYaml":"\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the *American Economic Review* in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nTo meticulously assess the influence of different incentives on donor behavior, Karlan and List structured their experiment with precision and thoroughness. Each recipient in the experiment was selected from a pool of individuals who had previously donated to the organization, ensuring that all participants had a baseline familiarity with and a prior engagement in charitable giving. The allocation of the letters was performed randomly to uphold the integrity of the experimental conditions and mitigate any selection bias. The key variation among the letters lay in the type of incentive they presented, which allowed the researchers to isolate the effect of these incentives from other factors that might influence a donor's decision to give. By embedding these variations subtly within the letters, the experiment not only preserved the naturalistic setting of the solicitation but also minimized any potential disruption to the donor's experience that could arise from overt experimental cues. This methodological rigor underpins the reliability of the study's findings, providing a clear lens through which to view how different motivational strategies affect the willingness of individuals to contribute financially to charitable causes.\n\n\nThis paper presents the results of a large-scale natural field experiment testing changes in revenue per solicitation and response rates given different types and levels of matching grants/gifts conditional on charitable giving. This is in order to provide insight to research in fundraising models and measures of non-market valuation for cost-benefit analyses. Of a sample of 50,083 individuals who have given to the organization since 1991, randomized and assigned 67% into \"match\" treatment group and 33% into control group, of which the \"match\" treatment group was offered a matching grant conditional on their donation. The \"match\" group was divded evenly between various sizes of the matching ratio (\\$3:\\$1, \\$2:\\$1, and \\$1:\\$1), the maximum size of the matching gift across all donations (\\$25,000, \\$50,000, and \\$100,000), and the example donation amount suggested to the donor (the individual's highest previous contribution, 1.25 times their highest previous contribution, and 1.5 times their highest previous contribution). All individuals received a four page letter identical in all respects except two: (a) the treatment let ters included an additional paragraph inserted at the top of the second page that announced that a \"concerned fellow member\" will match their donation, and (b) the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization. Outcome measures were donation response rates (donated or did not donate) and dollars donated.\n\nThis project seeks to replicate their results. However, because we are using a different software (R) to replicate the experiment. We got a different results because there are different estimators while we are running the probit, when in STATA we just need to use the command \"dprobit\".\n\n## Data\n\n### Description\n\n```{r include=FALSE}\n# Load necessary libraries\nlibrary(dplyr)     \nlibrary(ggplot2)  \nlibrary(foreign) \nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(broom)\nlibrary(stats)\n\n# Read the Stata data file into R\n\ndata <- read.dta(\"karlan_list_2007.dta\")\n```\n\n```{r include=FALSE}\n# Summary statistics for all observations\nsummary(data[, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n\n# Summary statistics for observations where treatment is 1\nsummary(data[data$treatment == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n\n# Summary statistics for observations where control is 1\nsummary(data[data$control == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\", \"female\")])\n```\n\n```{r echo=FALSE, warning=FALSE}\n# Convert necessary columns to numeric if they're not already\ndata$size <- as.numeric(data$size)\n\n# Calculate means for all observations\nmeans_all <- colMeans(data[, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Calculate means for observations where treatment is 1\nmeans_treatment <- colMeans(data[data$treatment == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Calculate means for observations where control is 1\nmeans_control <- colMeans(data[data$control == 1, c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\")])\n\n# Combine means into a data frame\nmeans_table <- data.frame(\n  Variable = c(\"treatment\", \"size\", \"ratio\", \"amount\", \"gave\"),\n  All_Observations = means_all,\n  Treatment = means_treatment,\n  Control = means_control\n)\n\n# Render the table nicely\nkable(means_table, \"html\") %>%\n  kable_styling(full_width = FALSE)\n```\n\n\n```{r echo=FALSE, warning=FALSE}\n\n# Create histogram\nhistogram <- ggplot(data, aes(x = amount, fill = treatment)) +\n  geom_histogram(binwidth = 1, position = \"dodge\", color = \"black\") +\n  labs(title = \"Amount of Donation by Treatment Group\", x = \"Amount\", y = \"Frequency\") +\n  facet_wrap(~ treatment) +  \n  theme_minimal()\n\n# Display histogram\nprint(histogram)\n```\n\n\n```{r echo=FALSE}\n# Create scatterplot matrix for selected continuous variables\nscatterplot_matrix <- ggplot(data, aes(x = mrm2, y = amount, color = ratio)) +\n  geom_point() +\n  labs(title = \"Scatterplot Matrix\", x = \"Number of months since last donation\", y = \"Amount\") +\n  theme_minimal()\n\nprint(scatterplot_matrix)\n```\n\n::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|-------------------|-----------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n:::\n\n### Balance Test\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n```{r echo=FALSE}\n# Define the variables to test\nvariables_to_test <- c(\"female\", \"couple\", \"dormant\", \"nonlit\", \"cases\", \"statecnt\", \"stateresponse\", \"red0\", \"blue0\", \"redcty\",\"pop_propurban\", \"psch_atlstba\", \"powner\", \"median_hhincome\", \"ave_hh_sz\", \"page18_39\", \"pblack\", \"pwhite\")\n\n# Initialize an empty data frame to store results\nbalance_table <- data.frame(Variable = character(),\n                            Diff = numeric(),\n                            p_Value = numeric(),\n                            stringsAsFactors = FALSE)\n\n# Loop over variables\nfor (var in variables_to_test) {\n  # T-Test\n  t_test_result <- t.test(as.numeric(data[[var]]) ~ data$treatment)\n  \n  # Linear Regression\n  reg_model <- lm(as.formula(paste(var, \"~ treatment\")), data = data)\n  tidy_reg <- tidy(reg_model)\n  \n  # Extract coefficients and p-values\n  reg_coefficient <- tidy_reg$estimate[2]  # treatment coefficient\n  reg_p_value <- tidy_reg$p.value[2]  # p-value for treatment\n  \n  # Update the balance table\n  balance_table <- rbind(balance_table, data.frame(\n    Variable = var,\n    Diff = reg_coefficient,\n    p_Value = reg_p_value\n  ))\n}\n\n# Print the balance table\n#print(balance_table)\n# Create the table using knitr and enhance it with kableExtra\nkable_table <- kable(balance_table, format = \"html\", caption = \"Balance Test Results\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE) %>%\n  column_spec(1, bold = TRUE, color = \"blue\") %>%  \n  column_spec(2:3, background = \"#f7f7f7\")  \n\nkable_table\n```\n\n\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n```{r echo=FALSE}\n\n# Compute proportions of people who donated in treatment and control groups\nprop_donated <- tapply(data$amount, data$treatment, mean)\n\n# Create barplot\nbarplot(prop_donated, \n        names.arg = c(\"Control\", \"Treatment\"), \n        xlab = \"Group\", \n        ylab = \"Proportion of Donated\",\n        col = c(\"blue\", \"green\"),\n        ylim = c(0, 1),\n        main = \"Proportion of Donated in Treatment and Control Groups\")\n```\n\n\n```{r echo=FALSE}\n\n# T-test between treatment and control groups\nttest_result <- t.test(amount ~ treatment, data = data)\n\n# Extract relevant information\nestimate <- ttest_result$estimate\np_value <- ttest_result$p.value\nconf_int <- ttest_result$conf.int\nconf_level <- attr(conf_int, \"conf.level\")\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Group\" = c(\"Control\", \"Treatment\"),\n  \"Estimate\" = estimate,\n  \"p-value\" = p_value\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n\n```\n\n\n```{r echo=FALSE}\n# Fit linear regression model\nmodel <- lm(amount ~ treatment, data = data)\n\n# Extract coefficients, standard errors, t-values, and p-values\ncoefficients <- summary(model)$coefficients[, 1]\nstd_errors <- summary(model)$coefficients[, 2]\nt_values <- summary(model)$coefficients[, 3]\np_values <- summary(model)$coefficients[, 4]\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Coefficient\" = coefficients,\n  \"Std. Error\" = std_errors,\n  \"T-value\" = t_values,\n  \"P-value\" = p_values\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n\n```\n\nThe previous table shows that there is a positive effect of the treatment on the proportion of donations, which is significant at 90% which does not make it statistically powerful.\n\n```{r include=FALSE}\n#*todo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.*\n# Model 1: Probit model without any subgroup analysis\nmodel1 <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"))\n# Calculate marginal effects\nmarginal_effects1 <- predict(model1, type = \"response\") * coef(model1)[\"amount\"]\n\n# Fit probit model\nmodel <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Display model summary\nsummary(model)\n\n# Model 2: Probit model for individuals where dormant == 1\nmodel2 <- glm(treatment ~ amount, data = subset(data, dormant == 1), family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n\n# Model 3: Probit model for individuals where dormant == 0\nmodel3 <- glm(treatment ~ amount, data = subset(data, dormant == 0), family = binomial(link = \"probit\"))\n\n\n# Summarize the results\n\nsummary(marginal_effects1) \nsummary(model)\nsummary(model2) \nsummary(model3)\n```\n\n### Replication of the model\n\n```{r echo=FALSE}\n# Fit probit model\nmodel <- glm(treatment ~ amount, data = data, family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Model 2: Probit model for individuals where dormant == 1\nmodel2 <- glm(treatment ~ amount, data = subset(data, dormant == 1), family = binomial(link = \"probit\"), control = glm.control(maxit = 100))\n\n# Model 3: Probit model for individuals where dormant == 0\nmodel3 <- glm(treatment ~ amount, data = subset(data, dormant == 0), family = binomial(link = \"probit\"))\n\n# Extract coefficients, standard errors, z-values, and p-values from model summaries\ncoef_model <- coef(summary(model))\ncoef_model2 <- coef(summary(model2))\ncoef_model3 <- coef(summary(model3))\n\n# Create a data frame to store the results\nresults <- data.frame(\n  \"Model\" = c(\"Model 1\", \"Model 2 (dormant == 1)\", \"Model 3 (dormant == 0)\"),\n  \"Estimate\" = c(coef_model[\"amount\", 1], coef_model2[\"amount\", 1], coef_model3[\"amount\", 1]),\n  \"Std. Error\" = c(coef_model[\"amount\", 2], coef_model2[\"amount\", 2], coef_model3[\"amount\", 2]),\n  \"Z-value\" = c(coef_model[\"amount\", 3], coef_model2[\"amount\", 3], coef_model3[\"amount\", 3]),\n  \"P-value\" = c(coef_model[\"amount\", 4], coef_model2[\"amount\", 4], coef_model3[\"amount\", 4])\n)\n\n# Print the table\nkable(results, format = \"markdown\")\n```\n\nThere is a problem with R because it gives a different estimator than the one that STATA provides and that does not allow to get the proper replication.\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n```{r include=FALSE}\n#*todo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the \"figures suggest\" comment the authors make on page 8?*\n\n# Subset the data for each match ratio group\ndata_ratio_1_1 <- subset(data, ratio2 == 0)  # Group where ratio is 1:1\ndata_ratio_2_1 <- subset(data, ratio2 == 1)  # Group where ratio is 2:1\n\n# Conduct t-test comparing donation rates between 1:1 match ratio group and 2:1 match ratio group\nttest_result <- t.test(amount ~ ratio2, data = data)\n\n# Display t-test results\nttest_result\n```\n\n```{r include=FALSE}\n# Subset the data based on match ratios\n#group_1_1 <- data$gave[data$match_ratio == \"1:1\"]\n#group_2_1 <- data$gave[data$match_ratio == \"2:1\"]\n#group_3_1 <- data$gave[data$match_ratio == \"3:1\"]\n\n# Perform t-tests\n#ttest_1_1_vs_2_1 <- t.test(group_1_1, group_2_1)\n#ttest_2_1_vs_3_1 <- t.test(group_2_1, group_3_1)\n\n# Output the results of the t-tests\n#print(ttest_1_1_vs_2_1)\n#print(ttest_2_1_vs_3_1)\n```\n\n\n```{r include=FALSE}\n#*todo: Assess the same issue using a regression. Specifically, create the variable `ratio1` then regress `gave` on `ratio1`, `ratio2`, and `ratio3` (or alternatively, regress `gave` on the categorical variable `ratio`). Interpret the coefficients and their statistical precision.*\n```\n\n\nIn analyzing the impact of different match ratios on the likelihood of donations using logistic regression, we observe varying degrees of effectiveness. The coefficients for the individual match ratios (ratio1, ratio2, and ratio3) indicate a progressive increase in the log odds of donating as the match ratio increases. Specifically, ratio1 (1:1 match) shows a very minimal increase in log odds (0.006564), suggesting that this match ratio barely affects the probability of donating compared to the baseline. In contrast, ratio2 (2:1 match) and ratio3 (3:1 match) exhibit more substantial effects with coefficients of 0.12244 and 0.12838, respectively, indicating a clearer positive influence on donation behavior. These coefficients suggest that higher match ratios are somewhat more effective at encouraging donations.\n\nThe full model, which assesses the collective impact of varying match ratios treated as a single categorical variable, shows a significant coefficient (0.08470). This significance indicates that different match ratios, when considered together, have a statistically significant effect on the likelihood of donating compared to the baseline. This outcome implies that while the individual effects of each match ratio are relatively modest, the overall strategy of employing match ratios is effective.\n\nHowever, the statistical precision of these coefficients, typically assessed by p-values and confidence intervals, is not detailed in the results provided. For a comprehensive interpretation, examining these statistical measures would be crucial. They would help confirm the reliability of the observed effects by showing the probability that these effects could be due to chance (p-values) and the range within which the true effects are likely to lie with a certain level of confidence (confidence intervals). Thus, while the regression results suggest some effectiveness of higher match ratios, a detailed examination of the statistical precision is essential to fully validate these conclusions.\n\n```{r echo=FALSE}\n# Logistic regression model\n# Create dummy variables\ndata$ratio1 <- ifelse(data$ratio == \"1\", 1, 0)\ndata$ratio2 <- ifelse(data$ratio == \"2\", 1, 0)\ndata$ratio3 <- ifelse(data$ratio == \"3\", 1, 0)\n\nmodel1 <- glm(gave ~ ratio1 , family = binomial(), data = data)\nsummary(model1)\n\nmodel2 <- glm(gave ~ ratio2 , family = binomial(), data = data)\nsummary(model2)\n\nmodel3 <- glm(gave ~ ratio3 , family = binomial(), data = data)\nsummary(model3)\n\nmodel <- glm(gave ~ ratio , family = binomial(), data = data)\nsummary(model)\n```\n\n```{r echo=FALSE}\n# Function to extract relevant data from model summary\nextract_model_info <- function(model) {\n  coef_table <- summary(model)$coefficients\n  data.frame(\n    Term = rownames(coef_table),\n    Estimate = coef_table[, \"Estimate\"],\n    Std_Error = coef_table[, \"Std. Error\"],\n    z_value = coef_table[, \"z value\"],\n    P_value = coef_table[, \"Pr(>|z|)\"],\n    stringsAsFactors = FALSE\n  )\n}\n\n# Extracting results for each model\nresults1 <- extract_model_info(model1)\nresults2 <- extract_model_info(model2)\nresults3 <- extract_model_info(model3)\n#results_full <- extract_model_info(model)\n\n# Add model identification\n#results1$Model <- \"Model 1 (ratio1)\"\n#results2$Model <- \"Model 2 (ratio2)\"\n#results3$Model <- \"Model 3 (ratio3)\"\n#results_full$Model <- \"Full Model (categorical ratio)\"\n\n# Combine all results into one data frame\nall_results <- rbind(results1, results2, results3)\n\n# Create a kable table and enhance it with kableExtra\nkable_table <- kable(all_results, format = \"html\", caption = \"Summary of Logistic Regression Models\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), full_width = FALSE) %>%\n  column_spec(1, bold = TRUE) %>%  # Make model column bold\n  column_spec(2:6, background = \"#f7f7f7\")  # Apply background color to data columns\n\n# Render the table in HTML\nkable_table\n```\n\n\n```{r echo=FALSE}\n#*todo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?*\n#*\n# 1. Direct calculation from the data\nresponse_rate_1 <- mean(data$gave[data$ratio == \"1\"])\nresponse_rate_2 <- mean(data$gave[data$ratio == \"2\"])\nresponse_rate_3 <- mean(data$gave[data$ratio == \"3\"])\n\ndiff_1_2 <- response_rate_2 - response_rate_1  # Difference between 1:1 and 2:1 match ratios\ndiff_2_3 <- response_rate_3 - response_rate_2  # Difference between 2:1 and 3:1 match ratios\n\n# Print direct computation results\nprint(paste(\"Direct Difference in response rates between 1:1 and 2:1 match ratios:\", diff_1_2))\nprint(paste(\"Direct Difference in response rates between 2:1 and 3:1 match ratios:\", diff_2_3))\n\n# 2. Logistic Regression to find differences using model coefficients\n# First, ensure 'ratio' is a factor if not already\ndata$ratio <- as.factor(data$ratio)\n\n# Fit the model\nmodel <- glm(gave ~ ratio, family = binomial(), data = data)\n\n# Print summary to view coefficient names\nprint(summary(model))\n\n# Coefficient interpretation (assuming '1' is the reference category)\nlog_odds_diff_1_2 <- coef(model)[\"ratio2\"]  # log odds of '2' relative to '1'\nlog_odds_diff_2_3 <- coef(model)[\"ratio3\"] - coef(model)[\"ratio2\"]  # log odds of '3' relative to '2'\n\n# Print model-based log odds differences\nprint(paste(\"Model-based Difference in log odds between 1:1 and 2:1 match ratios:\", log_odds_diff_1_2))\nprint(paste(\"Model-based Difference in log odds between 2:1 and 3:1 match ratios:\", log_odds_diff_2_3))\n\n# Convert log odds to probabilities for clearer interpretation\nprob_diff_1_2 <- exp(log_odds_diff_1_2) / (1 + exp(log_odds_diff_1_2))\nprob_diff_2_3 <- exp(log_odds_diff_2_3) / (1 + exp(log_odds_diff_2_3))\n\n# Print model-based probability differences\nprint(paste(\"Model-based Difference in probability estimates between 1:1 and 2:1 match ratios:\", prob_diff_1_2))\nprint(paste(\"Model-based Difference in probability estimates between 2:1 and 3:1 match ratios:\", prob_diff_2_3))\n```\n\nThe analysis of the effectiveness of different sizes of matched donations reveals minimal impact on increasing donor response rates. Direct comparison of response rates shows only a slight improvement when the match ratio is increased from 1:1 to 2:1, and an even smaller increase from 2:1 to 3:1, suggesting negligible practical benefits from increasing the match size within these ranges. Although the logistic regression model indicates a moderate improvement in log odds of donating when moving from a 1:1 to a 2:1 match ratio, this result does not align closely with the very small changes observed directly in the data. Furthermore, the probability changes suggested by the model seem overly optimistic and likely reflect a misunderstanding or misinterpretation of the log odds conversion. Overall, these findings suggest that larger match ratios, within the bounds studied, do not significantly enhance the likelihood of donations. This implies that non-profits might need to consider other strategies or focus on how match offers are communicated rather than simply increasing the match ratio to boost donor engagement.\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n```{r include=FALSE}\n#todo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?*\n\n# Load the broom package\nlibrary(broom)\n\n# Run the linear regression\nlm_model <- lm(amount ~ treatment, data = data)\n\n# Convert the summary of the linear regression model into a tidy data frame\ntidy_lm_model <- tidy(lm_model)\n\n```\n\nAs it was previously shown, the treatment improves the outcomes (amount of donations) in 15 percentage points and it is statistically significant at 90%. Therefore, we can rely on the fact that this type of intervention might result in a proper result.\n\n```{r results='asis', echo=FALSE}\nkable(tidy_lm_model)\n```\n\nBased on this constraint, where we are limiting the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. We can interpret that the treatment is negative, but not statistically significant. Therefore, if we implement this type of program, it would reduce the amount of donations.\n\n```{r include=FALSE}\n# Subset the data to include only people who made a donation\ndonation_data <- subset(data, gave == 1)\n\n# Run the linear regression\nlm_model_donation <- lm(amount ~ treatment, data = donation_data)\n\n# Print the regression summary\nsummary(lm_model_donation)\n\ntidy_lm_model_donation <- tidy(lm_model_donation)\n```\n\n```{r results='asis', echo=FALSE}\nkable(tidy_lm_model_donation)\n```\n\n\n```{r echo=FALSE}\n# Calculate sample average donation amount for treatment and control groups\navg_donation_treatment <- mean(donation_data$amount[donation_data$treatment == 1])\navg_donation_control <- mean(donation_data$amount[donation_data$treatment == 0])\n\n# Plot histogram for treatment group\nhist_treatment <- ggplot(donation_data[donation_data$treatment == 1, ], aes(x = amount)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  geom_vline(xintercept = avg_donation_treatment, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Treatment\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n# Plot histogram for control group\nhist_control <- ggplot(donation_data[donation_data$treatment == 0, ], aes(x = amount)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 20) +\n  geom_vline(xintercept = avg_donation_control, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Control\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n# Display plots side by side\ngrid.arrange(hist_treatment, hist_control, nrow = 1)\n```\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\nThe next graph shows that with higher number of observations it would be possible to get to the true value of the mean that should be expected to get if we have the population values. However, because it was worked with a sample, it is just an estimation\n\n```{r echo=FALSE}\n\n#*to do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You'll then calculate a vector of 10,000 differences, and then you'll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.*\n\n# Estimate mean and standard deviation for the control group\ncontrol_mean <- mean(data$control)\ncontrol_sd <- sd(data$control)\n\n# Estimate mean and standard deviation for the treatment group\ntreatment_mean <- mean(data$treatment)\ntreatment_sd <- sd(data$treatment)\n\n\n# Simulate draws from the control distribution\ncontrol_draws <- rnorm(10000, mean = control_mean, sd = control_sd)  # Assuming control_mean and control_sd are the mean and standard deviation of the control distribution\n\n# Simulate draws from the treatment distribution\ntreatment_draws <- rnorm(10000, mean = treatment_mean, sd = treatment_sd)  # Assuming treatment_mean and treatment_sd are the mean and standard deviation of the treatment distribution\n\n# Calculate vector of differences\ndifferences <- treatment_draws - control_draws\n\n# Calculate cumulative average of differences\ncumulative_avg <- cumsum(differences) / seq_along(differences)\n\n# Plot cumulative average of differences\nplot(cumulative_avg, type = \"l\", xlab = \"Number of Draws\", ylab = \"Cumulative Average Difference\", main = \"Cumulative Average Difference between Treatment and Control\")\n```\n\n\n### Central Limit Theorem\n\n```{r include=FALSE}\n# Function to simulate draws and calculate average difference\nsimulate_avg_difference <- function(sample_size, num_simulations) {\n  avg_differences <- numeric(num_simulations)\n  for (i in 1:num_simulations) {\n    control_draws <- rnorm(sample_size, mean = control_mean, sd = control_sd)\n    treatment_draws <- rnorm(sample_size, mean = treatment_mean, sd = treatment_sd)\n    avg_differences[i] <- mean(treatment_draws - control_draws)\n  }\n  return(avg_differences)\n}\n\n# Sample sizes\nsample_sizes <- c(50, 200, 500, 1000)\n\n# Number of simulations\nnum_simulations <- 1000\n\n# Plot histograms for each sample size\npar(mfrow = c(2, 2))  # Arrange plots in 2x2 grid\nfor (size in sample_sizes) {\n  avg_differences <- simulate_avg_difference(size, num_simulations)\n  hist(avg_differences, main = paste(\"Sample Size:\", size), xlab = \"Average Difference\", col = \"skyblue\", breaks = 30)\n}\n```\n\nIn the next graphs, it is possible to identify that with higher number observations the distribution becomes more efficient because it is concentrated in one spot where the true value of the populatoin should be identify. That would mean that the variance is lower than those situations where the sample is not big enough and that prevent to generate a good estimator. In those cases, the zero is located in the tail and when the sample increases, the zero is located out of the distribution which will mean that it would be an outlier.\n\n```{r echo=FALSE}\n\n#*to do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the \"middle\" of the distribution or whether it's in the \"tail.\"*\n\n# Function to simulate draws and calculate average difference\nsimulate_avg_difference <- function(sample_size, num_simulations) {\n  avg_differences <- numeric(num_simulations)\n  for (i in 1:num_simulations) {\n    control_draws <- rnorm(sample_size, mean = control_mean, sd = control_sd)\n    treatment_draws <- rnorm(sample_size, mean = treatment_mean, sd = treatment_sd)\n    avg_differences[i] <- mean(treatment_draws - control_draws)\n  }\n  return(avg_differences)\n}\n\n# Sample sizes\nsample_sizes <- c(50, 200, 500, 1000)\n\n# Number of simulations\nnum_simulations <- 1000\n\n# Plot histograms for each sample size\npar(mfrow = c(2, 2))  # Arrange plots in 2x2 grid\nfor (size in sample_sizes) {\n  avg_differences <- simulate_avg_difference(size, num_simulations)\n  hist(avg_differences, main = paste(\"Sample Size:\", size), xlab = \"Average Difference\", col = \"skyblue\", breaks = 30, xlim = c(0, 0.7))\n}\n```\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.553","theme":"cosmo","title":"A Replication of Karlan and List (2007)","author":"Daniel Garcia","date":"today","callout-appearance":"minimal"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}