[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Daniel Gomar",
    "section": "",
    "text": "##This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "{{&lt; pdf resume.pdf 100% 800 &gt;}}"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nDaniel Garcia\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKey Drivers Analysis\n\n\n\n\n\n\nDaniel Gomar\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMultinomial Logit Examples\n\n\n\n\n\n\nDaniel Gomar\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\n\n\nDaniel Garcia\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSegmentation Methods\n\n\n\n\n\n\nDaniel Gomar\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo meticulously assess the influence of different incentives on donor behavior, Karlan and List structured their experiment with precision and thoroughness. Each recipient in the experiment was selected from a pool of individuals who had previously donated to the organization, ensuring that all participants had a baseline familiarity with and a prior engagement in charitable giving. The allocation of the letters was performed randomly to uphold the integrity of the experimental conditions and mitigate any selection bias. The key variation among the letters lay in the type of incentive they presented, which allowed the researchers to isolate the effect of these incentives from other factors that might influence a donor’s decision to give. By embedding these variations subtly within the letters, the experiment not only preserved the naturalistic setting of the solicitation but also minimized any potential disruption to the donor’s experience that could arise from overt experimental cues. This methodological rigor underpins the reliability of the study’s findings, providing a clear lens through which to view how different motivational strategies affect the willingness of individuals to contribute financially to charitable causes.\nThis paper presents the results of a large-scale natural field experiment testing changes in revenue per solicitation and response rates given different types and levels of matching grants/gifts conditional on charitable giving. This is in order to provide insight to research in fundraising models and measures of non-market valuation for cost-benefit analyses. Of a sample of 50,083 individuals who have given to the organization since 1991, randomized and assigned 67% into “match” treatment group and 33% into control group, of which the “match” treatment group was offered a matching grant conditional on their donation. The “match” group was divded evenly between various sizes of the matching ratio ($3:$1, $2:$1, and $1:$1), the maximum size of the matching gift across all donations ($25,000, $50,000, and $100,000), and the example donation amount suggested to the donor (the individual’s highest previous contribution, 1.25 times their highest previous contribution, and 1.5 times their highest previous contribution). All individuals received a four page letter identical in all respects except two: (a) the treatment let ters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and (b) the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization. Outcome measures were donation response rates (donated or did not donate) and dollars donated.\nThis project seeks to replicate their results. However, because we are using a different software (R) to replicate the experiment. We got a different results because there are different estimators while we are running the probit, when in STATA we just need to use the command “dprobit”."
  },
  {
    "objectID": "projects/project1/index.html#introduction",
    "href": "projects/project1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nTo meticulously assess the influence of different incentives on donor behavior, Karlan and List structured their experiment with precision and thoroughness. Each recipient in the experiment was selected from a pool of individuals who had previously donated to the organization, ensuring that all participants had a baseline familiarity with and a prior engagement in charitable giving. The allocation of the letters was performed randomly to uphold the integrity of the experimental conditions and mitigate any selection bias. The key variation among the letters lay in the type of incentive they presented, which allowed the researchers to isolate the effect of these incentives from other factors that might influence a donor’s decision to give. By embedding these variations subtly within the letters, the experiment not only preserved the naturalistic setting of the solicitation but also minimized any potential disruption to the donor’s experience that could arise from overt experimental cues. This methodological rigor underpins the reliability of the study’s findings, providing a clear lens through which to view how different motivational strategies affect the willingness of individuals to contribute financially to charitable causes.\nThis paper presents the results of a large-scale natural field experiment testing changes in revenue per solicitation and response rates given different types and levels of matching grants/gifts conditional on charitable giving. This is in order to provide insight to research in fundraising models and measures of non-market valuation for cost-benefit analyses. Of a sample of 50,083 individuals who have given to the organization since 1991, randomized and assigned 67% into “match” treatment group and 33% into control group, of which the “match” treatment group was offered a matching grant conditional on their donation. The “match” group was divded evenly between various sizes of the matching ratio ($3:$1, $2:$1, and $1:$1), the maximum size of the matching gift across all donations ($25,000, $50,000, and $100,000), and the example donation amount suggested to the donor (the individual’s highest previous contribution, 1.25 times their highest previous contribution, and 1.5 times their highest previous contribution). All individuals received a four page letter identical in all respects except two: (a) the treatment let ters included an additional paragraph inserted at the top of the second page that announced that a “concerned fellow member” will match their donation, and (b) the reply card included in bold type the details of the match. For the control group, the reply card match language was replaced with a large logo of the organization. Outcome measures were donation response rates (donated or did not donate) and dollars donated.\nThis project seeks to replicate their results. However, because we are using a different software (R) to replicate the experiment. We got a different results because there are different estimators while we are running the probit, when in STATA we just need to use the command “dprobit”."
  },
  {
    "objectID": "projects/project1/index.html#data",
    "href": "projects/project1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\n\n\n\n\n\n\nVariable\nAll_Observations\nTreatment\nControl\n\n\n\n\ntreatment\ntreatment\n0.6668131\n1.0000000\n0.0000000\n\n\nsize\nsize\n2.6671126\n3.5001198\n1.0000000\n\n\nratio\nratio\n1.3335463\n1.9998802\n0.0000000\n\n\namount\namount\n0.9156939\n0.9668733\n0.8132678\n\n\ngave\ngave\n0.0206457\n0.0220386\n0.0178582\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\n\n\nBalance Test Results\n\n\nVariable\nDiff\np_Value\n\n\n\n\nfemale\n-0.0075469\n0.0786910\n\n\ncouple\n-0.0016169\n0.5593646\n\n\ndormant\n0.0008233\n0.8619565\n\n\nnonlit\n0.0317896\n0.0888347\n\n\ncases\n-0.0037492\n0.7332787\n\n\nstatecnt\n0.0090492\n0.8680680\n\n\nstateresponse\n0.0000065\n0.8951398\n\n\nred0\n0.0087268\n0.0607864\n\n\nblue0\n-0.0087268\n0.0607864\n\n\nredcty\n0.0042892\n0.3659008\n\n\npop_propurban\n0.0017984\n0.4719282\n\n\npsch_atlstba\n-0.0033333\n0.0645890\n\n\npowner\n0.0003536\n0.8499958\n\n\nmedian_hhincome\n-157.9254823\n0.4582830\n\n\nave_hh_sz\n0.0030122\n0.4098012\n\n\npage18_39\n-0.0001239\n0.9010291\n\n\npblack\n0.0001289\n0.9219351\n\n\npwhite\n-0.0009128\n0.5753077"
  },
  {
    "objectID": "projects/project1/index.html#experimental-results",
    "href": "projects/project1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup\nEstimate\np.value\n\n\n\n\nmean in group 0\nControl\n0.8132678\n0.0550856\n\n\nmean in group 1\nTreatment\n0.9668733\n0.0550856\n\n\n\n\n\n\n\n\n\n\n\nCoefficient\nStd..Error\nT.value\nP.value\n\n\n\n\n(Intercept)\n0.8132678\n0.0674184\n12.062995\n0.0000000\n\n\ntreatment\n0.1536055\n0.0825613\n1.860503\n0.0628203\n\n\n\n\n\nThe previous table shows that there is a positive effect of the treatment on the proportion of donations, which is significant at 90% which does not make it statistically powerful.\n\n\nReplication of the model\n\n\n\n\n\nModel\nEstimate\nStd..Error\nZ.value\nP.value\n\n\n\n\nModel 1\n0.0012825\n0.0006884\n1.862873\n0.0624801\n\n\nModel 2 (dormant == 1)\n0.0019747\n0.0012190\n1.619955\n0.1052420\n\n\nModel 3 (dormant == 0)\n0.0009494\n0.0008424\n1.127094\n0.2597027\n\n\n\n\n\nThere is a problem with R because it gives a different estimator than the one that STATA provides and that does not allow to get the proper replication.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nIn analyzing the impact of different match ratios on the likelihood of donations using logistic regression, we observe varying degrees of effectiveness. The coefficients for the individual match ratios (ratio1, ratio2, and ratio3) indicate a progressive increase in the log odds of donating as the match ratio increases. Specifically, ratio1 (1:1 match) shows a very minimal increase in log odds (0.006564), suggesting that this match ratio barely affects the probability of donating compared to the baseline. In contrast, ratio2 (2:1 match) and ratio3 (3:1 match) exhibit more substantial effects with coefficients of 0.12244 and 0.12838, respectively, indicating a clearer positive influence on donation behavior. These coefficients suggest that higher match ratios are somewhat more effective at encouraging donations.\nThe full model, which assesses the collective impact of varying match ratios treated as a single categorical variable, shows a significant coefficient (0.08470). This significance indicates that different match ratios, when considered together, have a statistically significant effect on the likelihood of donating compared to the baseline. This outcome implies that while the individual effects of each match ratio are relatively modest, the overall strategy of employing match ratios is effective.\nHowever, the statistical precision of these coefficients, typically assessed by p-values and confidence intervals, is not detailed in the results provided. For a comprehensive interpretation, examining these statistical measures would be crucial. They would help confirm the reliability of the observed effects by showing the probability that these effects could be due to chance (p-values) and the range within which the true effects are likely to lie with a certain level of confidence (confidence intervals). Thus, while the regression results suggest some effectiveness of higher match ratios, a detailed examination of the statistical precision is essential to fully validate these conclusions.\n\n\n\nCall:\nglm(formula = gave ~ ratio1, family = binomial(), data = data)\n\nCoefficients:\n             Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept) -3.860848   0.035657 -108.277   &lt;2e-16 ***\nratio1       0.006564   0.075444    0.087    0.931    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10071  on 50081  degrees of freedom\nAIC: 10075\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nCall:\nglm(formula = gave ~ ratio2, family = binomial(), data = data)\n\nCoefficients:\n            Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept) -3.88787    0.03612 -107.631   &lt;2e-16 ***\nratio2       0.12244    0.07324    1.672   0.0946 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10068  on 50081  degrees of freedom\nAIC: 10072\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nCall:\nglm(formula = gave ~ ratio3, family = binomial(), data = data)\n\nCoefficients:\n            Estimate Std. Error  z value Pr(&gt;|z|)    \n(Intercept) -3.88931    0.03614 -107.603   &lt;2e-16 ***\nratio3       0.12838    0.07315    1.755   0.0792 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10068  on 50081  degrees of freedom\nAIC: 10072\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nCall:\nglm(formula = gave ~ ratio, family = binomial(), data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.97694    0.05011  -79.36  &lt; 2e-16 ***\nratio        0.08470    0.02706    3.13  0.00175 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\n\nSummary of Logistic Regression Models\n\n\n\nTerm\nEstimate\nStd_Error\nz_value\nP_value\n\n\n\n\n(Intercept)\n(Intercept)\n-3.8608477\n0.0356570\n-108.2774869\n0.0000000\n\n\nratio1\nratio1\n0.0065639\n0.0754436\n0.0870035\n0.9306688\n\n\n(Intercept)1\n(Intercept)\n-3.8878718\n0.0361223\n-107.6308962\n0.0000000\n\n\nratio2\nratio2\n0.1224356\n0.0732446\n1.6715983\n0.0946036\n\n\n(Intercept)2\n(Intercept)\n-3.8893086\n0.0361448\n-107.6034226\n0.0000000\n\n\nratio3\nratio3\n0.1283843\n0.0731490\n1.7551061\n0.0792412\n\n\n\n\n\n\n\n\n\n\n[1] \"Direct Difference in response rates between 1:1 and 2:1 match ratios: 0.00188425102171499\"\n\n\n[1] \"Direct Difference in response rates between 2:1 and 3:1 match ratios: 0.000100023980252939\"\n\n\n\nCall:\nglm(formula = gave ~ ratio, family = binomial(), data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.00727    0.05844 -68.565  &lt; 2e-16 ***\nratio1       0.15299    0.08852   1.728  0.08394 .  \nratio2       0.24184    0.08646   2.797  0.00516 ** \nratio3       0.24635    0.08637   2.852  0.00434 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10060  on 50079  degrees of freedom\nAIC: 10068\n\nNumber of Fisher Scoring iterations: 6\n\n\n[1] \"Model-based Difference in log odds between 1:1 and 2:1 match ratios: 0.24183589557498\"\n\n\n[1] \"Model-based Difference in log odds between 2:1 and 3:1 match ratios: 0.00451192242813109\"\n\n\n[1] \"Model-based Difference in probability estimates between 1:1 and 2:1 match ratios: 0.56016602715118\"\n\n\n[1] \"Model-based Difference in probability estimates between 2:1 and 3:1 match ratios: 0.50112797869347\"\n\n\nThe analysis of the effectiveness of different sizes of matched donations reveals minimal impact on increasing donor response rates. Direct comparison of response rates shows only a slight improvement when the match ratio is increased from 1:1 to 2:1, and an even smaller increase from 2:1 to 3:1, suggesting negligible practical benefits from increasing the match size within these ranges. Although the logistic regression model indicates a moderate improvement in log odds of donating when moving from a 1:1 to a 2:1 match ratio, this result does not align closely with the very small changes observed directly in the data. Furthermore, the probability changes suggested by the model seem overly optimistic and likely reflect a misunderstanding or misinterpretation of the log odds conversion. Overall, these findings suggest that larger match ratios, within the bounds studied, do not significantly enhance the likelihood of donations. This implies that non-profits might need to consider other strategies or focus on how match offers are communicated rather than simply increasing the match ratio to boost donor engagement.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nAs it was previously shown, the treatment improves the outcomes (amount of donations) in 15 percentage points and it is statistically significant at 90%. Therefore, we can rely on the fact that this type of intervention might result in a proper result.\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n0.8132678\n0.0674184\n12.062995\n0.0000000\n\n\ntreatment\n0.1536055\n0.0825613\n1.860503\n0.0628203\n\n\n\nBased on this constraint, where we are limiting the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. We can interpret that the treatment is negative, but not statistically significant. Therefore, if we implement this type of program, it would reduce the amount of donations.\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n45.540269\n2.423378\n18.7920635\n0.0000000\n\n\ntreatment\n-1.668394\n2.872384\n-0.5808393\n0.5614756"
  },
  {
    "objectID": "projects/project1/index.html#simulation-experiment",
    "href": "projects/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThe next graph shows that with higher number of observations it would be possible to get to the true value of the mean that should be expected to get if we have the population values. However, because it was worked with a sample, it is just an estimation\n\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nIn the next graphs, it is possible to identify that with higher number observations the distribution becomes more efficient because it is concentrated in one spot where the true value of the populatoin should be identify. That would mean that the variance is lower than those situations where the sample is not big enough and that prevent to generate a good estimator. In those cases, the zero is located in the tail and when the sample increases, the zero is located out of the distribution which will mean that it would be an outlier."
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nBased on the previous histogram, we can observe that the patents are skewed to the left which does not show a normal distribution. Based on the analysis of the histograms and mean number of patents awarded to firms, we observe that firms using Blueprinty’s software, on average, have a higher number of patents (4 patents) compared to those not using the software (3.6 patents). The histograms likely show that the distribution for firms using Blueprinty is shifted slightly to the right, indicating a higher frequency of firms with a greater number of patents. This analysis, bolstered by the statistically significant results of the t-test, strongly suggests a positive association between the use of Blueprinty’s software and the number of patents awarded. The evidence supports the claim that using Blueprinty’s software may enhance a firm’s success in securing patents.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Number of Patents by Usage of Blueprinty Software\n\n\nUses Blueprinty\nMean Number of Patents\n\n\n\n\n0\n3.623177\n\n\n1\n4.091371\n\n\n\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers. After examining the data on age and regional distribution related to the status of Blueprinty software users, distinct patterns emerge that shed light on the user demographics and geographical preferences. Firms that use Blueprinty’s software have an average age of 24.15 years, which is notably younger than the 26.69 years for those that do not use the software. This indicates a trend where younger firms are more likely to embrace Blueprinty, potentially due to their greater openness to adopting innovative technologies or their different needs in managing patent applications effectively.\nThe regional analysis reveals a consistent trend across various U.S. regions: non-users of Blueprinty’s software significantly outnumber users. For example, in the Midwest, there are 207 non-users to just 17 users; in the Northeast, 488 non-users to 113 users; and this pattern holds in the Northwest, South, and Southwest as well. These figures suggest that while Blueprinty has a presence across these regions, its market penetration varies and remains relatively low compared to the potential number of firms that could benefit from its services.\nThe combination of these age and regional data points to a clear profile of Blueprinty’s current market which is younger firms across various regions, though still a minority among potential users. This demographic and regional information could be crucial for Blueprinty in tailoring its marketing strategies and product offerings. Specifically, it suggests a strategic opportunity to focus on younger firms and increase efforts in regions with lower adoption rates, possibly by addressing regional specific needs or barriers to adoption. Overall, the data provides a roadmap for potential growth and deeper market penetration for Blueprinty’s innovative software solutions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe log-likelihood function for a set of independent observations \\(y_1, y_2, \\ldots, y_n\\) from a Poisson distribution with parameter \\(\\lambda\\) is given by:\n\\[\n\\ell(\\lambda | y_1, y_2, \\ldots, y_n) = \\log L(\\lambda | y_1, y_2, \\ldots, y_n) = -n\\lambda + \\left(\\sum_{i=1}^n y_i\\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n\\]\n\n#Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example\npoisson_loglikelihood &lt;- function(lambda, Y) {\n    if(lambda &lt;= 0) {\n        return(-Inf)  # log-likelihood is -infinity if lambda is not positive\n    }\n    \n    # Calculate the log-likelihood for Poisson distribution\n    log_likelihood &lt;- -length(Y) * lambda + sum(Y * log(lambda)) - sum(lfactorial(Y))\n    return(log_likelihood)\n}\n\n\n\n\n\n\n\n\n\n\nGiven the log-likelihood function for a set of observations from a Poisson distribution: \\[\n\\ell(\\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i\\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n\\]\nThe first derivative with respect to () is: \\[\n\\frac{\\partial \\ell}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^n y_i}{\\lambda}\n\\]\nSetting this derivative equal to zero for maximization: \\[\n-n + \\frac{\\sum_{i=1}^n y_i}{\\lambda} = 0\n\\]\nSolving for (): \\[\n\\lambda = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\nThus, the MLE of () is the sample mean, (), which matches the expectation of the Poisson parameter: \\[\n\\lambda_{\\text{MLE}} = \\overline{y}\n\\]\n\n# Calculate the MLE for lambda, which is the mean of Y\nlambda_mle &lt;- mean(Y)\n\n# Output the result\nprint(paste(\"The MLE of lambda is:\", lambda_mle))\n\n[1] \"The MLE of lambda is: 3.68466666666667\"\n\n\n\n\n[1] \"The MLE of lambda is: 3.68466666668552\"\n\n\n[1] \"Optimization successful!\"\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdate your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that* \\(\\lambda_i = e^{X_i'\\beta}\\). For example:*\n\npoisson_regression_likelihood &lt;- function(beta, Y, X) {\n    lambda &lt;- exp(X %*% beta)\n    \n    log_likelihood &lt;- sum(Y * log(lambda) - lambda - lfactorial(Y))\n    \n    # Return the negative of log-likelihood because most R optimization functions minimize\n    return(-log_likelihood)\n}\n\n\n\n\n\nEstimated Coefficients and Standard Errors for Poisson Regression Model\n\n\n\nEstimate\nStandard Error\n\n\n\n\n(Intercept)\n-0.2008772\n0.1133793\n\n\nage\n0.1186880\n0.0063973\n\n\nI(age^2)\n-0.0022495\n0.0000772\n\n\nregionNortheast\n0.0206660\n0.0419832\n\n\nregionNorthwest\n-0.0115896\n0.0531043\n\n\nregionSouth\n-0.0814664\n0.0540337\n\n\nregionSouthwest\n0.0493809\n0.0467772\n\n\niscustomer\n0.0542006\n0.0407959\n\n\n\n\n\n\n\n\n\n\n\n\nGLM Poisson Regression Results\n\n\n\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n-0.4513\n0.1836\n-2.4576\n0.0140\n\n\nage\n0.1445\n0.0139\n10.4138\n0.0000\n\n\nI(age^2)\n-0.0029\n0.0003\n-11.1308\n0.0000\n\n\nregionNortheast\n0.0986\n0.0420\n2.3471\n0.0189\n\n\nregionNorthwest\n-0.0201\n0.0538\n-0.3736\n0.7087\n\n\nregionSouth\n0.0572\n0.0527\n1.0854\n0.2778\n\n\nregionSouthwest\n0.0513\n0.0472\n1.0876\n0.2768\n\n\niscustomer\n0.1181\n0.0389\n3.0348\n0.0024\n\n\n\n\n\n\n\n\nThe results from the Poisson regression models provide valuable insights into the factors influencing patent success among engineering firms. Notably, the use of Blueprinty’s software is significantly associated with increased patent counts. Specifically, the GLM analysis reveals that being a customer of Blueprinty’s software increases the log count of patents significantly, with a coefficient of 0.1181 (p = 0.0024), indicating a positive and statistically significant impact on patent awards when controlling for other factors. This finding supports the marketing claim that Blueprinty’s software enhances a firm’s ability to secure patents.\nAdditionally, the age of a firm and its squared term have significant effects on patent success, suggesting a quadratic relationship where patent activity increases with firm age up to a point before it begins to decline. This lifecycle effect is crucial for understanding the dynamics of innovation as firms mature. Regional differences also play a role, with firms in the Northeast experiencing higher patent counts compared to the baseline region, suggesting regional disparities in patent activities.\nOverall, these results underscore the effectiveness of Blueprinty’s software in boosting patent success, while also highlighting the importance of firm age and regional context in patent award dynamics. This analysis not only reinforces the value proposition of Blueprinty’s software but also provides strategic insights for targeting specific firm demographics and regions to maximize patent production."
  },
  {
    "objectID": "projects/project2/index.html#blueprinty-case-study",
    "href": "projects/project2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nBased on the previous histogram, we can observe that the patents are skewed to the left which does not show a normal distribution. Based on the analysis of the histograms and mean number of patents awarded to firms, we observe that firms using Blueprinty’s software, on average, have a higher number of patents (4 patents) compared to those not using the software (3.6 patents). The histograms likely show that the distribution for firms using Blueprinty is shifted slightly to the right, indicating a higher frequency of firms with a greater number of patents. This analysis, bolstered by the statistically significant results of the t-test, strongly suggests a positive association between the use of Blueprinty’s software and the number of patents awarded. The evidence supports the claim that using Blueprinty’s software may enhance a firm’s success in securing patents.\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean Number of Patents by Usage of Blueprinty Software\n\n\nUses Blueprinty\nMean Number of Patents\n\n\n\n\n0\n3.623177\n\n\n1\n4.091371\n\n\n\n\n\n\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers. After examining the data on age and regional distribution related to the status of Blueprinty software users, distinct patterns emerge that shed light on the user demographics and geographical preferences. Firms that use Blueprinty’s software have an average age of 24.15 years, which is notably younger than the 26.69 years for those that do not use the software. This indicates a trend where younger firms are more likely to embrace Blueprinty, potentially due to their greater openness to adopting innovative technologies or their different needs in managing patent applications effectively.\nThe regional analysis reveals a consistent trend across various U.S. regions: non-users of Blueprinty’s software significantly outnumber users. For example, in the Midwest, there are 207 non-users to just 17 users; in the Northeast, 488 non-users to 113 users; and this pattern holds in the Northwest, South, and Southwest as well. These figures suggest that while Blueprinty has a presence across these regions, its market penetration varies and remains relatively low compared to the potential number of firms that could benefit from its services.\nThe combination of these age and regional data points to a clear profile of Blueprinty’s current market which is younger firms across various regions, though still a minority among potential users. This demographic and regional information could be crucial for Blueprinty in tailoring its marketing strategies and product offerings. Specifically, it suggests a strategic opportunity to focus on younger firms and increase efforts in regions with lower adoption rates, possibly by addressing regional specific needs or barriers to adoption. Overall, the data provides a roadmap for potential growth and deeper market penetration for Blueprinty’s innovative software solutions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\n\\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe log-likelihood function for a set of independent observations \\(y_1, y_2, \\ldots, y_n\\) from a Poisson distribution with parameter \\(\\lambda\\) is given by:\n\\[\n\\ell(\\lambda | y_1, y_2, \\ldots, y_n) = \\log L(\\lambda | y_1, y_2, \\ldots, y_n) = -n\\lambda + \\left(\\sum_{i=1}^n y_i\\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n\\]\n\n#Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example\npoisson_loglikelihood &lt;- function(lambda, Y) {\n    if(lambda &lt;= 0) {\n        return(-Inf)  # log-likelihood is -infinity if lambda is not positive\n    }\n    \n    # Calculate the log-likelihood for Poisson distribution\n    log_likelihood &lt;- -length(Y) * lambda + sum(Y * log(lambda)) - sum(lfactorial(Y))\n    return(log_likelihood)\n}\n\n\n\n\n\n\n\n\n\n\nGiven the log-likelihood function for a set of observations from a Poisson distribution: \\[\n\\ell(\\lambda) = -n\\lambda + \\left(\\sum_{i=1}^n y_i\\right) \\log \\lambda - \\sum_{i=1}^n \\log(y_i!)\n\\]\nThe first derivative with respect to () is: \\[\n\\frac{\\partial \\ell}{\\partial \\lambda} = -n + \\frac{\\sum_{i=1}^n y_i}{\\lambda}\n\\]\nSetting this derivative equal to zero for maximization: \\[\n-n + \\frac{\\sum_{i=1}^n y_i}{\\lambda} = 0\n\\]\nSolving for (): \\[\n\\lambda = \\frac{\\sum_{i=1}^n y_i}{n}\n\\]\nThus, the MLE of () is the sample mean, (), which matches the expectation of the Poisson parameter: \\[\n\\lambda_{\\text{MLE}} = \\overline{y}\n\\]\n\n# Calculate the MLE for lambda, which is the mean of Y\nlambda_mle &lt;- mean(Y)\n\n# Output the result\nprint(paste(\"The MLE of lambda is:\", lambda_mle))\n\n[1] \"The MLE of lambda is: 3.68466666666667\"\n\n\n\n\n[1] \"The MLE of lambda is: 3.68466666668552\"\n\n\n[1] \"Optimization successful!\"\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nUpdate your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g() to be exp() so that* \\(\\lambda_i = e^{X_i'\\beta}\\). For example:*\n\npoisson_regression_likelihood &lt;- function(beta, Y, X) {\n    lambda &lt;- exp(X %*% beta)\n    \n    log_likelihood &lt;- sum(Y * log(lambda) - lambda - lfactorial(Y))\n    \n    # Return the negative of log-likelihood because most R optimization functions minimize\n    return(-log_likelihood)\n}\n\n\n\n\n\nEstimated Coefficients and Standard Errors for Poisson Regression Model\n\n\n\nEstimate\nStandard Error\n\n\n\n\n(Intercept)\n-0.2008772\n0.1133793\n\n\nage\n0.1186880\n0.0063973\n\n\nI(age^2)\n-0.0022495\n0.0000772\n\n\nregionNortheast\n0.0206660\n0.0419832\n\n\nregionNorthwest\n-0.0115896\n0.0531043\n\n\nregionSouth\n-0.0814664\n0.0540337\n\n\nregionSouthwest\n0.0493809\n0.0467772\n\n\niscustomer\n0.0542006\n0.0407959\n\n\n\n\n\n\n\n\n\n\n\n\nGLM Poisson Regression Results\n\n\n\nEstimate\nStd. Error\nz value\nPr(&gt;|z|)\n\n\n\n\n(Intercept)\n-0.4513\n0.1836\n-2.4576\n0.0140\n\n\nage\n0.1445\n0.0139\n10.4138\n0.0000\n\n\nI(age^2)\n-0.0029\n0.0003\n-11.1308\n0.0000\n\n\nregionNortheast\n0.0986\n0.0420\n2.3471\n0.0189\n\n\nregionNorthwest\n-0.0201\n0.0538\n-0.3736\n0.7087\n\n\nregionSouth\n0.0572\n0.0527\n1.0854\n0.2778\n\n\nregionSouthwest\n0.0513\n0.0472\n1.0876\n0.2768\n\n\niscustomer\n0.1181\n0.0389\n3.0348\n0.0024\n\n\n\n\n\n\n\n\nThe results from the Poisson regression models provide valuable insights into the factors influencing patent success among engineering firms. Notably, the use of Blueprinty’s software is significantly associated with increased patent counts. Specifically, the GLM analysis reveals that being a customer of Blueprinty’s software increases the log count of patents significantly, with a coefficient of 0.1181 (p = 0.0024), indicating a positive and statistically significant impact on patent awards when controlling for other factors. This finding supports the marketing claim that Blueprinty’s software enhances a firm’s ability to secure patents.\nAdditionally, the age of a firm and its squared term have significant effects on patent success, suggesting a quadratic relationship where patent activity increases with firm age up to a point before it begins to decline. This lifecycle effect is crucial for understanding the dynamics of innovation as firms mature. Regional differences also play a role, with firms in the Northeast experiencing higher patent counts compared to the baseline region, suggesting regional disparities in patent activities.\nOverall, these results underscore the effectiveness of Blueprinty’s software in boosting patent success, while also highlighting the importance of firm age and regional context in patent award dynamics. This analysis not only reinforces the value proposition of Blueprinty’s software but also provides strategic insights for targeting specific firm demographics and regions to maximize patent production."
  },
  {
    "objectID": "projects/project2/index.html#airbnb-case-study",
    "href": "projects/project2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nDescriptive\n\n# Visualize distributions of numerical variables\nggplot(airbnb_data, aes(x = price)) + geom_histogram(bins = 30) + ggtitle(\"Distribution of Prices\")\n\n\n\n\n\n\n\n\n\n# Histogram of the Number of Reviews\nggplot(airbnb_data, aes(x = number_of_reviews)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribution of Number of Reviews\", x = \"Number of Reviews\", y = \"Count\")\n\n\n\n\n\n\n\n# Histogram of Bedrooms\nggplot(airbnb_data, aes(x = bedrooms)) +\n  geom_histogram(bins = 10, fill = \"coral\", color = \"black\") +\n  labs(title = \"Distribution of Bedrooms\", x = \"Number of Bedrooms\", y = \"Count\")\n\n\n\n\n\n\n\n# Histogram of Bathrooms\nggplot(airbnb_data, aes(x = bathrooms)) +\n  geom_histogram(bins = 10, fill = \"lightgreen\", color = \"black\") +\n  labs(title = \"Distribution of Bathrooms\", x = \"Number of Bathrooms\", y = \"Count\")\n\n\n\n\n\n\n\n\n\nggplot(airbnb_data, aes(x = price, y = number_of_reviews)) +\n  geom_point(alpha = 0.5, color = \"blue\") +\n  labs(title = \"Price vs. Number of Reviews\", x = \"Price ($)\", y = \"Number of Reviews\")\n\n\n\n\n\n\n\n\n\n# Explore relationships between number of reviews and other features\nggplot(airbnb_data, aes(x = bedrooms, y = number_of_reviews)) + geom_point() + ggtitle(\"Bedrooms vs. Number of Reviews\")\n\n\n\n\n\n\n\n\n\nggplot(airbnb_data, aes(x = instant_bookable, fill = instant_bookable)) +\n  geom_bar() +\n  labs(title = \"Effect of Instant Bookable Feature on Listing Counts\", x = \"Instant Bookable\", y = \"Count of Listings\")\n\n\n\n\n\n\n\n\n\n\nAnalysis\n\n# Fit the model\npoisson_model &lt;- glm(number_of_reviews ~ bedrooms + bathrooms + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable, family = poisson(link = \"log\"), data = airbnb_data)\n\n# Check summary\nsummary(poisson_model)\n\n\nCall:\nglm(formula = number_of_reviews ~ bedrooms + bathrooms + price + \n    review_scores_cleanliness + review_scores_location + review_scores_value + \n    instant_bookable, family = poisson(link = \"log\"), data = airbnb_data)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                3.543e+00  1.579e-02 224.421   &lt;2e-16 ***\nbedrooms                   7.818e-02  1.963e-03  39.823   &lt;2e-16 ***\nbathrooms                 -1.286e-01  3.723e-03 -34.532   &lt;2e-16 ***\nprice                      1.134e-05  7.409e-06   1.531    0.126    \nreview_scores_cleanliness  1.135e-01  1.490e-03  76.217   &lt;2e-16 ***\nreview_scores_location    -7.547e-02  1.600e-03 -47.159   &lt;2e-16 ***\nreview_scores_value       -9.159e-02  1.792e-03 -51.114   &lt;2e-16 ***\ninstant_bookableTRUE       3.319e-01  2.880e-03 115.214   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 961626  on 30159  degrees of freedom\nResidual deviance: 937449  on 30152  degrees of freedom\nAIC: 1058932\n\nNumber of Fisher Scoring iterations: 6\n\n\nTThe fitted Poisson regression model offers significant insights into the dynamics affecting the number of reviews on Airbnb listings, with the intercept showing a substantial baseline log count of reviews of 3.543 when all predictors are held constant. This high intercept suggests that even in the absence of any enhancing factors, listings inherently attract a baseline level of reviews.\nDelving into the effects of specific variables, it is clear that larger properties, as indicated by the number of bedrooms, tend to attract more reviews, with each additional bedroom leading to a roughly 7.82% increase in the number of reviews. This trend underscores the preference or need among Airbnb users for more spacious accommodations, which likely accommodate larger groups who may be more engaged in leaving feedback. In contrast, an increase in the number of bathrooms tends to reduce the number of reviews by about 12.86%. This might suggest that properties with disproportionately more bathrooms than bedrooms are perceived as offering less value, particularly to larger groups who are key contributors to reviews. The impact of pricing on reviews is minimal and statistically insignificant, indicating that the nightly rate, within the range observed in the dataset, does little to influence the frequency of reviews. This might point to price sensitivity being less critical than other factors in determining guest satisfaction or engagement.\nReview scores significantly affect the number of reviews, with cleanliness being particularly critical. Each additional point in cleanliness scores correlates with an 11.35% increase in reviews, highlighting the paramount importance guests place on cleanliness. However, higher location and value scores are associated with fewer reviews. This could reflect a scenario where high expectations set by top ratings in these categories are not always met, or perhaps satisfaction in these areas leads to less perceived need among guests to provide feedback.\nThe feature of instant bookability markedly enhances the number of reviews, with listings offering this option seeing a 33.19% increase in reviews compared to those without it. The convenience of instant booking appears to be a significant draw for guests, leading to higher engagement in terms of reviews.While the model’s Akaike Information Criterion (AIC) and residual deviance indicate a good fit, there is room for improvement. This could potentially be achieved by incorporating interaction terms or exploring other unobserved factors that might refine the understanding of what drives reviews on Airbnb.\nOverall, the model elucidates several key insights: practical features like more bedrooms and instant bookability tend to increase reviews, while more subjective assessments such as location and value can detract from them if guest expectations are not managed appropriately. The critical role of cleanliness in driving review counts cannot be overstated. This comprehensive analysis can assist hosts in focusing on the attributes most valued by guests, potentially guiding enhancements that lead to more bookings and feedback, thereby boosting the visibility and success of their listings\n\nnb_model &lt;- glm.nb(number_of_reviews ~ bedrooms + bathrooms + price + review_scores_cleanliness + review_scores_location + review_scores_value + instant_bookable, data = airbnb_data)\n\n# Check summary\nsummary(nb_model)\n\n\nCall:\nglm.nb(formula = number_of_reviews ~ bedrooms + bathrooms + price + \n    review_scores_cleanliness + review_scores_location + review_scores_value + \n    instant_bookable, data = airbnb_data, init.theta = 0.7009228771, \n    link = log)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                4.185e+00  9.319e-02  44.906  &lt; 2e-16 ***\nbedrooms                   7.398e-02  1.125e-02   6.577 4.80e-11 ***\nbathrooms                 -1.139e-01  2.020e-02  -5.639 1.71e-08 ***\nprice                      6.427e-06  3.983e-05   0.161    0.872    \nreview_scores_cleanliness  1.982e-01  8.034e-03  24.671  &lt; 2e-16 ***\nreview_scores_location    -1.090e-01  9.391e-03 -11.606  &lt; 2e-16 ***\nreview_scores_value       -2.117e-01  1.047e-02 -20.220  &lt; 2e-16 ***\ninstant_bookableTRUE       3.261e-01  1.762e-02  18.512  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.7009) family taken to be 1)\n\n    Null deviance: 35554  on 30159  degrees of freedom\nResidual deviance: 34579  on 30152  degrees of freedom\nAIC: 242074\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.70092 \n          Std. Err.:  0.00521 \n\n 2 x log-likelihood:  -242056.42700 \n\n\nThe analysis conducted using the Negative Binomial regression model reveals significant insights about the factors that influence the number of reviews on Airbnb listings. The model, robust in its statistical significance and precision, illuminates the impacts of various property characteristics on guest engagement. The intercept of the model is notably high and statistically significant, indicating a substantial baseline number of reviews independent of the property features. This high baseline suggests that listings on Airbnb tend to attract a certain level of reviews due to the platform’s inherent popularity and the active participation of its user base.\nAmong the variables analyzed, the number of bedrooms in a property shows a positive correlation with the number of reviews. Specifically, each additional bedroom is associated with a significant increase in the expected number of reviews, highlighting that larger properties, which typically accommodate more guests, are more likely to receive feedback, possibly due to the increased likelihood of group travels or family stays. An increase in the number of bathrooms tends to decrease the number of reviews. This negative association might suggest that properties with a higher number of bathrooms relative to their bedrooms do not provide proportional value or appeal, especially if these additional bathrooms lead to higher rental prices without corresponding benefits. The pricing variable shows a very small and statistically insignificant effect on the number of reviews, indicating that price fluctuations within the observed range do not significantly impact guest decisions to leave reviews. This suggests that guests’ decisions to review are driven more by their experiences than by cost considerations.\nReview scores also play a critical role in influencing reviews. High cleanliness scores are particularly impactful, with each point increase leading to a substantial rise in the number of reviews. This underscores the importance of cleanliness in guest satisfaction and their propensity to leave feedback. In contrast, higher scores for location and value are associated with fewer reviews. This could be due to the high expectations set by such scores not being met or that guests satisfied with the location and value may feel less compelled to leave feedback. The feature of instant bookability significantly boosts the number of reviews, with listings offering this option seeing a marked increase in reviews compared to those that do not. The convenience and ease of booking facilitated by this feature likely encourage more bookings and consequently, more reviews.\nOverall, the model demonstrates a good fit, as evidenced by the AIC and the closeness of the null and residual deviances, suggesting it captures the variation in review numbers well. The significant theta value, indicating the appropriateness of the Negative Binomial model over simpler models, points to the presence of overdispersion in the count data, which this model adequately addresses.\nIn conclusion, the findings reveal that while practical amenities like additional bedrooms and instant bookability enhance review counts, subjective assessments such as location and value can detract from them if not managed properly. Cleanliness emerges as a key driver of reviews, highlighting an area where hosts can focus their efforts to boost guest satisfaction and attract more reviews. This comprehensive analysis provides actionable insights for Airbnb hosts aiming to optimize their listings and improve guest experiences."
  },
  {
    "objectID": "projects/project3/index.html",
    "href": "projects/project3/index.html",
    "title": "Multinomial Logit Examples",
    "section": "",
    "text": "This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans."
  },
  {
    "objectID": "projects/project3/index.html#estimating-yogurt-preferences",
    "href": "projects/project3/index.html#estimating-yogurt-preferences",
    "title": "Multinomial Logit Examples",
    "section": "1. Estimating Yogurt Preferences",
    "text": "1. Estimating Yogurt Preferences\n\nLikelihood for the Multi-nomial Logit (MNL) Model\nSuppose we have \\(i=1,\\ldots,n\\) consumers who each select exactly one product \\(j\\) from a set of \\(J\\) products. The outcome variable is the identity of the product chosen \\(y_i \\in \\{1, \\ldots, J\\}\\) or equivalently a vector of \\(J-1\\) zeros and \\(1\\) one, where the \\(1\\) indicates the selected product. For example, if the third product was chosen out of 4 products, then either \\(y=3\\) or \\(y=(0,0,1,0)\\) depending on how we want to represent it. Suppose also that we have a vector of data on each product \\(x_j\\) (eg, size, price, etc.).\nWe model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:\n\\[ U_{ij} = x_j'\\beta + \\epsilon_{ij} \\]\nwhere \\(\\epsilon_{ij}\\) is an i.i.d. extreme value error term.\nThe choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer \\(i\\) chooses product \\(j\\):\n\\[ \\mathbb{P}_i(j) = \\frac{e^{x_j'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nFor example, if there are 4 products, the probability that consumer \\(i\\) chooses product 3 is:\n\\[ \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{e^{x_1'\\beta} + e^{x_2'\\beta} + e^{x_3'\\beta} + e^{x_4'\\beta}} \\]\nA clever way to write the individual likelihood function for consumer \\(i\\) is the product of the \\(J\\) probabilities, each raised to the power of an indicator variable (\\(\\delta_{ij}\\)) that indicates the chosen product:\n\\[ L_i(\\beta) = \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} = \\mathbb{P}_i(1)^{\\delta_{i1}} \\times \\ldots \\times \\mathbb{P}_i(J)^{\\delta_{iJ}}\\]\nNotice that if the consumer selected product \\(j=3\\), then \\(\\delta_{i3}=1\\) while \\(\\delta_{i1}=\\delta_{i2}=\\delta_{i4}=0\\) and the likelihood is:\n\\[ L_i(\\beta) = \\mathbb{P}_i(1)^0 \\times \\mathbb{P}_i(2)^0 \\times \\mathbb{P}_i(3)^1 \\times \\mathbb{P}_i(4)^0 = \\mathbb{P}_i(3) = \\frac{e^{x_3'\\beta}}{\\sum_{k=1}^Je^{x_k'\\beta}} \\]\nThe joint likelihood (across all consumers) is the product of the \\(n\\) individual likelihoods:\n\\[ L_n(\\beta) = \\prod_{i=1}^n L_i(\\beta) = \\prod_{i=1}^n \\prod_{j=1}^J \\mathbb{P}_i(j)^{\\delta_{ij}} \\]\nAnd the joint log-likelihood function is:\n\\[ \\ell_n(\\beta) = \\sum_{i=1}^n \\sum_{j=1}^J \\delta_{ij} \\log(\\mathbb{P}_i(j)) \\]\n\n\nYogurt Dataset\nWe will use the yogurt_data dataset, which provides anonymized consumer identifiers (id), a vector indicating the chosen product (y1:y4), a vector indicating if any products were “featured” in the store as a form of advertising (f1:f4), and the products’ prices (p1:p4). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1’s purchase. Consumers 2 through 7 each bought yogurt 2, etc.\n\n\n# A tibble: 6 × 13\n     id    y1    y2    y3    y4    f1    f2    f3    f4    p1     p2     p3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1     0     0     0     1     0     0     0     0 0.108 0.081  0.0610\n2     2     0     1     0     0     0     0     0     0 0.108 0.0980 0.0640\n3     3     0     1     0     0     0     0     0     0 0.108 0.0980 0.0610\n4     4     0     1     0     0     0     0     0     0 0.108 0.0980 0.0610\n5     5     0     1     0     0     0     0     0     0 0.125 0.0980 0.0490\n6     6     0     1     0     0     0     0     0     0 0.108 0.092  0.0500\n# ℹ 1 more variable: p4 &lt;dbl&gt;\n\n\nDescription of the yogurt data\nThis dataset contains the following variables:\n-id: anonymized consumer identifiers -y: indicator variables showing which yogurt was purchased -f: indicator variables showing if a yogurt was featured in the store -p: continous variables indicating the prices of the yogurts\nEach row in the dataset represents a unique purchase made by a consumer, and each set of columns (y1 to y4, f1 to f4, p1 to p4) pertains to the characteristics of the four yogurt products.\nLet the vector of product features include brand dummy variables for yogurts 1-3 (we’ll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts’ prices:\n\\[ x_j' = [\\mathbbm{1}(\\text{Yogurt 1}), \\mathbbm{1}(\\text{Yogurt 2}), \\mathbbm{1}(\\text{Yogurt 3}), X_f, X_p] \\]\nThe “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer \\(i\\), covariate \\(k\\), and product \\(j\\)) instead of the typical 2 dimensions for cross-sectional regression models (consumer \\(i\\) and covariate \\(k\\)).\nWhat we would like to do is reorganize the data from a “wide” shape with \\(n\\) rows and multiple columns for each covariate, to a “long” shape with \\(n \\times J\\) rows and a single column for each covariate. As part of this re-organization, we’ll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be “pivoted” or “melted” from wide to long.\n\n\nEstimation\n\n\n\n\n\n\n\nParameter\nEstimate\n\n\n\n\nIntercept Yogurt 1\n1.4119707\n\n\nIntercept Yogurt 2\n0.6523545\n\n\nIntercept Yogurt 3\n-3.0846259\n\n\nFeatured\n0.3268772\n\n\nPrice\n-37.5763842\n\n\n\n\n\n\n\n\n\n\n\nDiscussion\nThe estimated parameters for the intercepts of the three yogurts provide insight into consumer preferences for each yogurt type. These intercepts represent the baseline utility that consumers derive from each yogurt product before considering the effects of features such as being featured in the store or the price. The intercept values indicate the relative preference for each yogurt product. Higher intercepts suggest a higher baseline utility, which corresponds to a stronger inherent preference by consumers for that product, assuming other factors (like being featured or price) are constant. Yogurt 1, with an intercept of 1.4119707, has the highest baseline utility among the three products. This indicates that, all else being equal, consumers have the strongest inherent preference for Yogurt 1.\nYogurt 2, with an intercept of 0.6523545, also has a positive baseline utility, but it is lower than that of Yogurt 1. This suggests that consumers have a moderate preference for Yogurt 2. While it is preferred over Yogurt 3, it does not enjoy as strong a preference as Yogurt 1. In contrast, Yogurt 3 has an intercept of -3.0846259, which is a negative value. This indicates a significantly lower baseline utility compared to Yogurt 1 and Yogurt 2. Consequently, Yogurt 3 is the least preferred product among the three.\nIn general, the intercepts suggest that, in the absence of other factors, consumers have a strong preference for Yogurt 1, a moderate preference for Yogurt 2, and a significantly lower preference for Yogurt 3. This ranking provides valuable information for retailers and manufacturers, indicating that efforts to promote Yogurt 1 may capitalize on its existing strong preference, while strategies to improve the attractiveness of Yogurt 3 could be explored to enhance its competitive position in the market.\n\n\nDollar Benefit Calculation\nThe dollar benefit between the most-preferred yogurt (Yogurt 1) and the least-preferred yogurt (Yogurt 3) can be calculated using the utility difference and the dollar-per-util conversion factor.\nGiven the utility difference:\n\\[\n\\Delta U = \\text{Intercept Yogurt 1} - \\text{Intercept Yogurt 3}\n\\]\nand the dollar-per-util conversion factor:\n\\[\n\\text{Dollar-per-Util Conversion Factor} = \\frac{1}{|\\beta_{\\text{price}}|}\n\\]\nThe dollar benefit is calculated as:\n\\[\n\\text{Dollar Benefit} = \\Delta U \\times \\text{Dollar-per-Util Conversion Factor} = ( \\text{Intercept Yogurt 1} - \\text{Intercept Yogurt 3} ) \\times \\frac{1}{|\\beta_{\\text{price}}|}\n\\]\nSubstituting the values:\n\\[\n\\text{Dollar Benefit} = (1.4119707 - (-3.0846259)) \\times \\frac{1}{37.5763842} = 4.4965966 \\times \\frac{1}{37.5763842} \\approx 0.11965\n\\]\nThe dollar benefit between the most-preferred yogurt (Yogurt 1) and the least-preferred yogurt (Yogurt 3) is approximately $0.12 per unit. This value represents the per-unit monetary measure of brand value, indicating how much more consumers value Yogurt 1 over Yogurt 3.\nOne benefit of the MNL model is that we can simulate counterfactuals (eg, what if the price of yogurt 1 was $0.10/oz instead of $0.08/oz).\n\n\n\n\n\n\n\nProduct\nInitial Market Share\nNew Market Share\nChange\n\n\n\n\n1\n0.6542172\n0.0230716\n-0.6311455\n\n\n2\n0.4710059\n0.7175646\n0.2465587\n\n\n3\n0.0288812\n0.0438084\n0.0149273\n\n\n4\n0.2463129\n0.3728599\n0.1265470\n\n\n\n\n\n\n\n\n\nWhen the price of Yogurt 1 is increased by $0.10, its market share drops dramatically from 65.4% to 2.3%. This indicates a strong price sensitivity among consumers for Yogurt 1. The significant decrease of approximately 63.1% in market share suggests that consumers are highly responsive to price changes for this product, and many switch to other yogurt options when the price of Yogurt 1 increases. Additionally, the market shares for the other yogurts increase as a result of this price change. This redistribution of market shares indicates that when the price of Yogurt 1 rises, consumers shift their preferences to the other available yogurts, with the largest portion shifting to Yogurt 2 and a smaller but notable shift to Yogurt 4. Therefore, the results clearly show that increasing the price of Yogurt 1 by $0.10 leads to a substantial decrease in its market share, highlighting the high price elasticity of demand for this yogurt. Consumers readily switch to alternative products when faced with a price increase for Yogurt 1."
  },
  {
    "objectID": "projects/project3/index.html#estimating-minivan-preferences",
    "href": "projects/project3/index.html#estimating-minivan-preferences",
    "title": "Multinomial Logit Examples",
    "section": "2. Estimating Minivan Preferences",
    "text": "2. Estimating Minivan Preferences\n\nData\nThis is how the dataset looks like:\n\n\n  resp.id ques alt carpool seat cargo  eng price choice\n1       1    1   1     yes    6   2ft  gas    35      0\n2       1    1   2     yes    8   3ft  hyb    30      0\n3       1    1   3     yes    6   3ft  gas    30      1\n4       1    2   1     yes    6   2ft  gas    30      0\n5       1    2   2     yes    7   3ft  gas    35      1\n6       1    2   3     yes    6   2ft elec    35      0\n\n\nBased on the information collected, we know that:\n\n\nNumber of respondents: 200 \n\n\nNumber of choice tasks per respondent: 0.075 \n\n\nNumber of alternatives per choice task: 3 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).\n\n\nModel\n\n\n\n\n\n\n\n\nVariable\nCoefficient\nStd. Error\n\n\n\n\nIntercept\n5.532174\n0.224186\n\n\nC(seat, Treatment(reference=“6”))[T.7]\n-0.524752\n0.059634\n\n\nC(seat, Treatment(reference=“6”))[T.8]\n-0.293085\n0.058510\n\n\nC(cargo, Treatment(reference=“2ft”))[T.3ft]\n0.438538\n0.048706\n\n\nC(eng, Treatment(reference=“gas”))[T.elec]\n-1.434680\n0.061794\n\n\nC(eng, Treatment(reference=“gas”))[T.hyb]\n-0.760489\n0.056919\n\n\nprice\n-0.159133\n0.006212\n\n\n\n\n\nResults\nThe intercept in the multinomial logistic regression model has a coefficient of 5.532174 with a standard error of 0.224186. This value represents the baseline log-odds of choosing a car with the reference features (6 seats, 2ft cargo space, and a gas engine) when the price is hypothetically zero. It serves as the starting point against which other features are compared.\nFor the number of seats, the model shows that cars with 7 or 8 seats are less preferred compared to those with 6 seats. Specifically, the coefficient for cars with 7 seats is -0.524752 with a standard error of 0.059634, indicating a significant decrease in preference. Similarly, the coefficient for cars with 8 seats is -0.293085 with a standard error of 0.058510. Although cars with 8 seats are also less preferred than those with 6 seats, they are slightly more favored than cars with 7 seats.Regarding cargo space, the model reveals that cars with 3ft of cargo space are more preferred than those with 2ft. The positive coefficient of 0.438538 (standard error of 0.048706) for 3ft cargo space indicates a higher likelihood of choosing cars with larger cargo space compared to the reference level.\nThe engine type significantly influences preferences as well. Cars with gas engines are the most preferred. The coefficient for electric engines is -1.434680 with a standard error of 0.061794, showing a strong negative impact on preference. This suggests that electric engines are much less favored compared to gas engines. Hybrid engines also have a negative coefficient of -0.760489 (standard error of 0.056919), indicating they are less preferred than gas engines, but more so than electric engines. The price coefficient is -0.159133 with a standard error of 0.006212. This negative coefficient signifies that as the price of a car increases, the likelihood of it being chosen decreases. This finding aligns with common expectations that higher prices generally reduce consumer demand.\nIn general, the data shows that the most preferred car features are 6 seats, 3ft cargo space, and a gas engine. Conversely, increasing the number of seats to 7 or 8 reduces preference, with 7 seats being the least favored. Additionally, cars with electric engines are the least preferred, followed by hybrid engines, with gas engines being the most preferred. Lower prices also significantly enhance the likelihood of a car being chosen. This analysis provides valuable insights into customer preferences, which can guide product design and marketing strategies to better align with consumer demand.\nThe dollar value of having 3ft of cargo space compared to 2ft of cargo space is approximately $2.76. This means that customers are willing to pay about $2.76 more for a car with 3ft of cargo space compared to one with 2ft of cargo space. This result comes from the fact that the coefficient for 3ft space is 0.438538 and the price coefficient is -0.159133. Then, we know that the dollar-per-util is 1/|0.159133|, which will be 6.285 approximately. Finally, we just need to multiply the coefficient for 3ft space times the dollar-per-util, that will give us 2.76.\n\n\n\nMinivan\nSeats\nCargo\nEngine\nPrice\n\n\n\n\nA\n7\n2\nHyb\n30\n\n\nB\n6\n2\nGas\n30\n\n\nC\n8\n2\nGas\n30\n\n\nD\n7\n3\nGas\n40\n\n\nE\n6\n2\nElec\n40\n\n\nF\n7\n2\nHyb\n35\n\n\n\n\n\nPredicted Market Shares for Minivans\nTo predict the market shares of the six minivans, we used the following utility calculation equation:\n\\[\nU_i = \\text{Intercept} + \\sum (\\text{Feature Coefficient} \\times \\text{Feature Value}) + (\\text{Price Coefficient} \\times \\text{Price})\n\\]\nUsing this equation, we calculated the utilities for each minivan and then applied the softmax function to determine the market shares. The results are summarized in the table below:\n\n\n\nMinivan\nMarket Share\n\n\n\n\nA\n11.61%\n\n\nB\n41.95%\n\n\nC\n31.30%\n\n\nD\n7.84%\n\n\nE\n2.04%\n\n\nF\n5.25%\n\n\n\nThe utility values for each minivan were calculated as follows:\n\nMinivan A (Seats: 7, Cargo: 2ft, Engine: Hybrid, Price: 30) \\[\nU_A = 5.532174 + (-0.524752) + 0 + (-0.760489) + (-0.159133 \\times 30) = -0.526056\n\\]\nMinivan B (Seats: 6, Cargo: 2ft, Engine: Gas, Price: 30) \\[\nU_B = 5.532174 + 0 + 0 + 0 + (-0.159133 \\times 30) = 0.758184\n\\]\nMinivan C (Seats: 8, Cargo: 2ft, Engine: Gas, Price: 30) \\[\nU_C = 5.532174 + (-0.293085) + 0 + 0 + (-0.159133 \\times 30) = 0.465099\n\\]\nMinivan D (Seats: 7, Cargo: 3ft, Engine: Gas, Price: 40) \\[\nU_D = 5.532174 + (-0.524752) + 0.438538 + 0 + (-0.159133 \\times 40) = -0.91936\n\\]\nMinivan E (Seats: 6, Cargo: 2ft, Engine: Elec, Price: 40) \\[\nU_E = 5.532174 + 0 + 0 + (-1.434680) + (-0.159133 \\times 40) = -2.267826\n\\]\nMinivan F (Seats: 7, Cargo: 2ft, Engine: Hybrid, Price: 35) \\[\nU_F = 5.532174 + (-0.524752) + 0 + (-0.760489) + (-0.159133 \\times 35) = -1.323222\n\\]\n\nAfter calculating these utility values, we transformed them using the softmax function to derive the market shares. The conclusion of the analysis shows that Minivan B is expected to capture the largest market share at 41.95%, followed by Minivan C with 31.30%. Minivans A, D, F, and E capture smaller shares, with Minivan E being the least preferred at 2.04%."
  },
  {
    "objectID": "projects/project4/index.html",
    "href": "projects/project4/index.html",
    "title": "Key Drivers Analysis",
    "section": "",
    "text": "This post implements a few measure of variable importance, interpreted as a key drivers analysis, for certain aspects of a payment card on customer satisfaction with that payment card.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDriver Analysis Results\n\n\n\n\n\n\n\n\n\n\n\nUsefulness\nMean_Decrease_Gini\nShapley_Values\nStandardized_Coefficients\nPearson_Correlation\n\n\n\n\ntrust\n0.0216111\n21.90763\n0\n0.4231501\n0.2557055\n\n\nbuild\n0.0071913\n16.83014\n0\n0.0857640\n0.1918957\n\n\ndiffers\n0.0072914\n17.53526\n0\n0.1535754\n0.1848009\n\n\neasy\n0.0092876\n17.16105\n0\n0.0672460\n0.2129847\n\n\nappealing\n0.0091606\n18.39372\n0\n0.0970753\n0.2079965\n\n\nrewarding\n0.0068401\n17.37851\n0\n0.0622599\n0.1945615\n\n\npopular\n0.0056425\n16.12860\n0\n0.0714742\n0.1714253\n\n\nservice\n0.0184053\n21.08278\n0\n0.3324903\n0.2510982\n\n\nimpact\n0.0235822\n24.63011\n0\n0.5542286\n0.2545386\n\n\n\n\n\nThe analysis of the dataset aimed to identify the key drivers of customer satisfaction using various statistical and machine learning techniques. The predictors included trust, build, differs, easy, appealing, rewarding, popular, service, and impact. Among these, trust and impact emerged as the most significant predictors across multiple metrics. Trust showed the highest Pearson correlation (0.2557) and a strong standardized coefficient (0.4232), indicating a robust linear relationship and significant influence on satisfaction. Impact also demonstrated high importance with the highest standardized coefficient (0.5542) and the highest mean decrease in Gini (25.3324) from the random forest model, underscoring its critical role in reducing model uncertainty. In terms of usefulness, which measures relative contribution to model performance, impact (0.0236) and trust (0.0216) again ranked highest. Conversely, predictors such as popular, rewarding, and build showed relatively lower importance across all metrics.\nInterestingly, the Shapley values, intended to measure the average marginal contribution of each predictor, were zero for all variables, suggesting potential issues with the model’s complexity or the data quality. This anomaly indicates the need for further investigation into the Shapley value calculation or the model’s capability to capture predictor contributions. Overall, trust and impact consistently stood out as the primary drivers of customer satisfaction in the dataset, highlighting areas where strategic improvements could be most beneficial\n\n\n\nDriver Analysis Results\n\n\n\nXGBoost_Importance\n\n\n\n\ntrust\n0.2793983\n\n\nbuild\n0.0734265\n\n\ndiffers\n0.0585575\n\n\neasy\n0.0703501\n\n\nappealing\n0.0606389\n\n\nrewarding\n0.0708004\n\n\npopular\n0.0651801\n\n\nservice\n0.1503828\n\n\nimpact\n0.1712655\n\n\n\n\n\nThe XGBoost model further confirmed these findings, with trust (0.2794) and impact (0.1713) having the highest importance scores, reinforcing their critical roles in influencing customer satisfaction."
  },
  {
    "objectID": "projects/project5/hw5_questions.html",
    "href": "projects/project5/hw5_questions.html",
    "title": "Segmentation Methods",
    "section": "",
    "text": "The data preparation step involves selecting only the numerical columns from the Iris dataset, specifically the first four columns, which contain the measurements of the flower attributes (Sepal Length, Sepal Width, Petal Length, Petal Width). This subset is stored in the variable data. Next, the initial centers for the k-means algorithm are determined by randomly selecting ‘k’ samples from the dataset. The seed is set to 42 to ensure reproducibility, and ‘k’ is chosen to be 3, reflecting the desired number of clusters. These initial centers are used to run the custom k-means algorithm.\nThe function plot_kmeans_steps is defined to visualize the steps of the k-means algorithm. It takes the dataset, the history of cluster centers, and the history of cluster assignments as inputs. The function iterates through the recorded steps of the algorithm. For each step, it creates a plot showing the data points colored by their cluster assignments and the cluster centers marked distinctly. The plot is titled with the corresponding step number, allowing for a clear visualization of the algorithm’s progress over iterations.\nFinally, the visualization function plot_kmeans_steps is called with the data and the histories of the centers and clusters obtained from running the custom k-means algorithm. This produces a series of plots that illustrate how the clusters and their centers evolve at each iteration, providing a detailed view of the algorithm’s operation\nTo compare the results of the custom k-means algorithm with the built-in kmeans function in R, we first set the seed to 42 to ensure reproducibility. We then run the kmeans function on the dataset with ‘k’ set to 3, matching the number of clusters used in the custom implementation. The results of the kmeans function, including the cluster assignments and the final cluster centers, are stored in the variable kmeans_result.\nNext, the data is prepared for visualization. The dataset is converted to a data frame, and a new column Cluster is added to indicate the cluster assignment for each data point as determined by the kmeans function. Similarly, the cluster centers are converted to a data frame, with an additional Cluster column to identify each center.\nUsing ggplot2, a scatter plot is created to visualize the clustering results. The data points are plotted with colors corresponding to their cluster assignments, and the cluster centers are highlighted with a different shape and size for clear distinction. The plot is titled “Built-in kmeans result,” providing a direct visual comparison of the clustering outcome from the built-in kmeans function against the custom algorithm implementation."
  },
  {
    "objectID": "projects/project5/hw5_questions.html#k-means",
    "href": "projects/project5/hw5_questions.html#k-means",
    "title": "Segmentation Methods",
    "section": "",
    "text": "The data preparation step involves selecting only the numerical columns from the Iris dataset, specifically the first four columns, which contain the measurements of the flower attributes (Sepal Length, Sepal Width, Petal Length, Petal Width). This subset is stored in the variable data. Next, the initial centers for the k-means algorithm are determined by randomly selecting ‘k’ samples from the dataset. The seed is set to 42 to ensure reproducibility, and ‘k’ is chosen to be 3, reflecting the desired number of clusters. These initial centers are used to run the custom k-means algorithm.\nThe function plot_kmeans_steps is defined to visualize the steps of the k-means algorithm. It takes the dataset, the history of cluster centers, and the history of cluster assignments as inputs. The function iterates through the recorded steps of the algorithm. For each step, it creates a plot showing the data points colored by their cluster assignments and the cluster centers marked distinctly. The plot is titled with the corresponding step number, allowing for a clear visualization of the algorithm’s progress over iterations.\nFinally, the visualization function plot_kmeans_steps is called with the data and the histories of the centers and clusters obtained from running the custom k-means algorithm. This produces a series of plots that illustrate how the clusters and their centers evolve at each iteration, providing a detailed view of the algorithm’s operation\nTo compare the results of the custom k-means algorithm with the built-in kmeans function in R, we first set the seed to 42 to ensure reproducibility. We then run the kmeans function on the dataset with ‘k’ set to 3, matching the number of clusters used in the custom implementation. The results of the kmeans function, including the cluster assignments and the final cluster centers, are stored in the variable kmeans_result.\nNext, the data is prepared for visualization. The dataset is converted to a data frame, and a new column Cluster is added to indicate the cluster assignment for each data point as determined by the kmeans function. Similarly, the cluster centers are converted to a data frame, with an additional Cluster column to identify each center.\nUsing ggplot2, a scatter plot is created to visualize the clustering results. The data points are plotted with colors corresponding to their cluster assignments, and the cluster centers are highlighted with a different shape and size for clear distinction. The plot is titled “Built-in kmeans result,” providing a direct visual comparison of the clustering outcome from the built-in kmeans function against the custom algorithm implementation."
  },
  {
    "objectID": "projects/project5/hw5_questions.html#latent-class-mnl",
    "href": "projects/project5/hw5_questions.html#latent-class-mnl",
    "title": "Segmentation Methods",
    "section": "Latent-Class MNL",
    "text": "Latent-Class MNL\ntodo: Use the Yogurt dataset from HW3 to estimate a latent-class MNL model. This model was formally introduced in the paper by Kamakura & Russell (1989), which you may want to read or reference. Compare the results to the standard (aggregate) MNL model from HW3. What are the differences in the parameter estimates?\ntodo: Fit the latent-class MNL model with 2, 3, …, K classes. How many classes are suggested by the BIC? The Bayesian-Schwarz Information Criterion link is a metric that assess the benefit of a better log likelihood at the expense of additional parameters to estimate – akin to the adjusted R-squared for the linear regression model. Note, however, that a lower BIC indicates a better model fit, accounting for the number of parameters in the model."
  },
  {
    "objectID": "projects/project5/hw5_questions.html#within-cluster-sum-of-squares-and-silhouette-scores",
    "href": "projects/project5/hw5_questions.html#within-cluster-sum-of-squares-and-silhouette-scores",
    "title": "Segmentation Methods",
    "section": "Within-cluster-sum-of-squares and silhouette scores",
    "text": "Within-cluster-sum-of-squares and silhouette scores\nThe first step in this code involves preparing the data by selecting only the numerical columns from the Iris dataset, specifically the first four columns which contain the measurements of the flower attributes (Sepal Length, Sepal Width, Petal Length, Petal Width). This subset is stored in the variable data.\nTwo functions are defined to evaluate clustering performance: calculate_wcss and calculate_silhouette_score. The calculate_wcss function computes the Within-Cluster Sum of Squares (WCSS) for a given number of clusters ‘k’. It performs k-means clustering on the dataset and returns the sum of the within-cluster variances. The calculate_silhouette_score function computes the average silhouette score for a given number of clusters ‘k’. It uses the silhouette function from the cluster package to calculate the silhouette width for each data point and returns the average silhouette score across all points.\nTo analyze how these metrics vary with different numbers of clusters, vectors are initialized to store the WCSS values and silhouette scores for a range of cluster counts from 2 to 7. A loop iterates over this range, calling the calculate_wcss and calculate_silhouette_score functions for each value of ‘k’, and storing the results in the corresponding vectors.\nFinally, the code generates a plot to visualize the relationship between the number of clusters and the WCSS. Using ggplot2, a line plot with points is created, where the x-axis represents the number of clusters and the y-axis represents the WCSS. The plot is titled “WCSS vs Number of Clusters,” providing a clear visualization of how the WCSS changes as the number of clusters increases, which can help in determining the optimal number of clusters through the “elbow method.”\n\n\n\n\n\n\n\n\n\nThe next graph contains code that aims to visualize the relationship between the number of clusters and the average silhouette score, which is a measure of how similar each point is to its own cluster compared to other clusters. The silhouette scores for different values of ‘k’ (the number of clusters) have been calculated previously and stored in the silhouette_scores vector, with the corresponding cluster counts stored in the k_values vector.\nTo create the plot, the ggplot2 package is used. The data is organized into a data frame containing the number of clusters (k) and the corresponding average silhouette scores (silhouette). Using ggplot, a line plot with points is generated, where the x-axis represents the number of clusters and the y-axis represents the average silhouette score. The plot is titled “Silhouette Score vs Number of Clusters,” providing a clear visualization of how the average silhouette score changes as the number of clusters varies. This visualization helps in identifying the optimal number of clusters by locating the peak silhouette score, indicating the best cluster configuration.\n\n\n\n\n\n\n\n\n\nTo determine the optimal number of clusters, the code evaluates two metrics: the Within-Cluster Sum of Squares (WCSS) and the average silhouette score. The k_values vector contains the different cluster counts that were evaluated, while the wcss_values and silhouette_scores vectors hold the corresponding WCSS and silhouette scores, respectively.\nThe optimal number of clusters based on the WCSS is identified by finding the index of the minimum WCSS value in the wcss_values vector. This index is then used to select the corresponding number of clusters from the k_values vector, and the result is stored in the variable optimal_k_wcss.\nSimilarly, the optimal number of clusters based on the silhouette score is determined by finding the index of the maximum silhouette score in the silhouette_scores vector. The corresponding number of clusters from the k_values vector is selected and stored in the variable optimal_k_silhouette.\nFinally, a list is created to return both optimal cluster counts: optimal_k_wcss and optimal_k_silhouette. This provides a clear and concise summary of the optimal number of clusters according to both evaluation metrics, facilitating the decision-making process for choosing the best cluster configuration\n\n\n$optimal_k_wcss\n[1] 7\n\n$optimal_k_silhouette\n[1] 2"
  }
]